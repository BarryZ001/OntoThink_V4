#!/usr/bin/env python3
"""
OntoThink ç‡§åŸT20ä¸€é”®è®­ç»ƒç®¡ç†å™¨
"""

import os
import subprocess
import json
import argparse
from pathlib import Path
import time

class OntoThinkEnflameTrainer:
    def __init__(self):
        # è‡ªåŠ¨æ£€æµ‹è¿è¡Œç¯å¢ƒ
        current_dir = Path.cwd()
        if "OntoThink_V4" in str(current_dir):
            # æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
            while current_dir.name != "OntoThink_V4" and current_dir.parent != current_dir:
                current_dir = current_dir.parent
            self.ontothink_root = current_dir
        else:
            # é»˜è®¤è·¯å¾„
            self.ontothink_root = Path("/workspace/code/OntoThink_V4")
        
        self.enflame_root = self.ontothink_root / "enflame_training"
        self.backend_data = self.ontothink_root / "backend" / "data" / "processed"
        
    def check_environment(self) -> bool:
        """æ£€æŸ¥ç‡§åŸT20ç¯å¢ƒ"""
        print("ğŸ” æ£€æŸ¥ç‡§åŸT20ç¯å¢ƒ...")
        
        # æ£€æŸ¥ç‡§åŸå·¥å…·åŒ…
        enflame_tools = self.ontothink_root / "FromEnflame"
        if not enflame_tools.exists():
            print("âŒ æœªæ‰¾åˆ°ç‡§åŸå·¥å…·åŒ…")
            return False
        
        # æ£€æŸ¥LLMè„šæœ¬æ˜¯å¦å¯ç”¨
        llm_scripts_paths = [
            enflame_tools / "ai_development_toolkit" / "distributed",
            enflame_tools / "distributed" / "llm_scripts_1.0.40",
            self.enflame_root / "llm_scripts"
        ]
        
        llm_scripts_found = False
        for llm_path in llm_scripts_paths:
            if llm_path.exists():
                print(f"âœ… æ‰¾åˆ°LLMè„šæœ¬ç›®å½•: {llm_path}")
                llm_scripts_found = True
                break
        
        if not llm_scripts_found:
            print("âš ï¸  ç‡§åŸLLMè„šæœ¬æœªæ‰¾åˆ°ï¼Œæ­£åœ¨é…ç½®...")
            return self.setup_environment()
        
        print("âœ… ç‡§åŸT20ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        return True
    
    def setup_environment(self) -> bool:
        """é…ç½®ç‡§åŸT20ç¯å¢ƒ"""
        print("ğŸ”§ é…ç½®ç‡§åŸT20ç¯å¢ƒ...")
        
        setup_script = self.enflame_root / "setup_enflame_env.sh"
        if not setup_script.exists():
            print("âŒ ç¯å¢ƒé…ç½®è„šæœ¬ä¸å­˜åœ¨")
            return False
        
        try:
            # è¿è¡Œç¯å¢ƒé…ç½®è„šæœ¬
            os.chmod(setup_script, 0o755)
            result = subprocess.run([str(setup_script)], capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… ç‡§åŸT20ç¯å¢ƒé…ç½®å®Œæˆ")
                return True
            else:
                print(f"âŒ ç¯å¢ƒé…ç½®å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ ç¯å¢ƒé…ç½®å¼‚å¸¸: {e}")
            return False
    
    def prepare_data(self) -> bool:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“Š å‡†å¤‡ç‡§åŸT20è®­ç»ƒæ•°æ®...")
        
        # æ£€æŸ¥OntoThinkåŸå§‹æ•°æ®
        if not self.backend_data.exists():
            print("âŒ æœªæ‰¾åˆ°OntoThinkåŸå§‹æ•°æ®")
            return False
        
        # æ£€æŸ¥æ˜¯å¦å·²è½¬æ¢
        enflame_data_dir = self.enflame_root / "datasets" / "ontothink_multiturn"
        train_file = enflame_data_dir / "train.jsonl"
        
        if train_file.exists():
            print("âœ… ç‡§åŸæ ¼å¼æ•°æ®å·²å­˜åœ¨")
            return True
        
        # è¿è¡Œæ•°æ®è½¬æ¢
        prepare_script = self.enflame_root / "scripts" / "prepare_enflame_data.py"
        
        cmd = [
            "python3", str(prepare_script),
            "--input_dir", str(self.backend_data),
            "--output_dir", str(enflame_data_dir),
            "--format", "multiturn"
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
                return True
            else:
                print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {result.stderr}")
                return False
        except Exception as e:
            print(f"âŒ æ•°æ®å‡†å¤‡å¼‚å¸¸: {e}")
            return False
    
    def download_model_if_needed(self) -> bool:
        """æ£€æŸ¥å¹¶ä¸‹è½½ChatGLM3æ¨¡å‹"""
        model_dir = self.enflame_root / "models" / "THUDM" / "chatglm3-6b"
        
        if model_dir.exists() and (model_dir / "config.json").exists():
            print("âœ… ChatGLM3-6Bæ¨¡å‹å·²å­˜åœ¨")
            return True
        
        print("ğŸ“¥ ChatGLM3-6Bæ¨¡å‹ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½...")
        print("ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½ChatGLM3-6Bæ¨¡å‹åˆ°ä»¥ä¸‹è·¯å¾„:")
        print(f"   {model_dir}")
        print("ğŸ”— ä¸‹è½½å‘½ä»¤:")
        print(f"   cd {model_dir.parent}")
        print("   git clone https://huggingface.co/THUDM/chatglm3-6b")
        print("\næˆ–ä½¿ç”¨HuggingFace Hub:")
        print("   from transformers import AutoModel")
        print("   model = AutoModel.from_pretrained('THUDM/chatglm3-6b')")
        
        return False
    
    def start_training(self) -> bool:
        """å¯åŠ¨è®­ç»ƒ"""
        print("ğŸš€ å¯åŠ¨OntoThinkç‡§åŸT20è®­ç»ƒ...")
        
        training_script = self.enflame_root / "scripts" / "ontothink_chatglm3_enflame.sh"
        
        if not training_script.exists():
            print("âŒ è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨")
            return False
        
        try:
            # è®¾ç½®æ‰§è¡Œæƒé™
            os.chmod(training_script, 0o755)
            
            # å¯åŠ¨è®­ç»ƒ
            print("ğŸ”¥ å¼€å§‹è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶...")
            result = subprocess.run([str(training_script)], cwd=str(self.enflame_root))
            
            return result.returncode == 0
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def run_full_pipeline(self) -> bool:
        """è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        print("ğŸ¯ OntoThink ç‡§åŸT20è®­ç»ƒæµç¨‹å¼€å§‹")
        print("=" * 60)
        
        steps = [
            ("æ£€æŸ¥ç‡§åŸT20ç¯å¢ƒ", self.check_environment),
            ("å‡†å¤‡è®­ç»ƒæ•°æ®", self.prepare_data),
            ("æ£€æŸ¥ChatGLM3æ¨¡å‹", self.download_model_if_needed),
            ("å¯åŠ¨æ¨¡å‹è®­ç»ƒ", self.start_training)
        ]
        
        for step_name, step_func in steps:
            print(f"\nğŸ“‹ æ­¥éª¤: {step_name}")
            if not step_func():
                print(f"âŒ {step_name}å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
                return False
            print(f"âœ… {step_name}å®Œæˆ")
        
        print("\nğŸ‰ OntoThinkç‡§åŸT20è®­ç»ƒæµç¨‹å®Œæˆï¼")
        return True

def main():
    parser = argparse.ArgumentParser(description="OntoThinkç‡§åŸT20è®­ç»ƒç®¡ç†å™¨")
    parser.add_argument("--step", choices=[
        "check", "prepare", "download", "train", "full"
    ], default="full", help="æ‰§è¡Œæ­¥éª¤")
    
    args = parser.parse_args()
    
    trainer = OntoThinkEnflameTrainer()
    
    if args.step == "check":
        trainer.check_environment()
    elif args.step == "prepare":
        trainer.prepare_data()
    elif args.step == "download":
        trainer.download_model_if_needed()
    elif args.step == "train":
        trainer.start_training()
    elif args.step == "full":
        trainer.run_full_pipeline()

if __name__ == "__main__":
    main()
