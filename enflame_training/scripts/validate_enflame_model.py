#!/usr/bin/env python3
"""
OntoThink ç‡§åŸT20è®­ç»ƒæ¨¡å‹éªŒè¯è„šæœ¬
"""

import json
import argparse
import sys
import os
from pathlib import Path
from typing import List, Dict

# æ·»åŠ ç‡§åŸcollieè·¯å¾„
sys.path.append("../llm_scripts")

try:
    import torch
    import ptex
    from transformers import AutoTokenizer
    from collie import ChatGLM2ForCausalLM, CollieConfig
except ImportError as e:
    print(f"âŒ å¯¼å…¥ç‡§åŸåº“å¤±è´¥: {e}")
    print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…ç‡§åŸT20ç¯å¢ƒå’Œä¾èµ–åº“")
    sys.exit(1)

class OntoThinkEnflameValidator:
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        
    def load_model(self):
        """åŠ è½½ç‡§åŸè®­ç»ƒçš„æ¨¡å‹"""
        print(f"ğŸ”„ åŠ è½½ç‡§åŸT20è®­ç»ƒçš„æ¨¡å‹: {self.model_path}")
        
        try:
            # åŠ è½½é…ç½®
            config = CollieConfig.from_pretrained(self.model_path, trust_remote_code=True)
            
            # åŠ è½½tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path, 
                trust_remote_code=True
            )
            
            # åŠ è½½æ¨¡å‹
            self.model = ChatGLM2ForCausalLM.from_pretrained(
                self.model_path,
                config=config,
                trust_remote_code=True
            )
            
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def generate_response(self, question: str, max_length: int = 2048) -> str:
        """ç”ŸæˆOntoThinkå›ç­”"""
        if not self.model or not self.tokenizer:
            return "æ¨¡å‹æœªåŠ è½½"
        
        # æ„å»ºOntoThinkæ ¼å¼çš„prompt
        prompt = f"""ä½ æ˜¯OntoThinkä¸“ä¸šæ€è¾¨åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå“²å­¦é—®é¢˜å¹¶ç”Ÿæˆå¤šç»´åº¦æ€è¾¨å›¾è°±ã€‚

è¯·ä¸ºä»¥ä¸‹å“²å­¦é—®é¢˜ç”Ÿæˆå®Œæ•´çš„æ€è¾¨å›¾è°±ï¼ŒåŒ…å«ä¸åŒç«‹åœºã€æ”¯æŒè®ºæ®å’Œåé—®ã€‚è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚

é—®é¢˜ï¼š{question}

è¯·ç”Ÿæˆç¬¦åˆä»¥ä¸‹æ ¼å¼çš„æ€è¾¨å›¾è°±ï¼š
```json
{{
  "question": "é—®é¢˜",
  "standpoints": [
    {{
      "id": "standpoint_1",
      "text": "ç«‹åœº1",
      "arguments": [
        {{"id": "argument_1_1", "text": "è®ºæ®1"}},
        {{"id": "argument_1_2", "text": "è®ºæ®2"}}
      ]
    }}
  ],
  "counter_questions": [
    {{"id": "counter_question_1", "text": "åé—®1"}}
  ]
}}
```"""
        
        try:
            # ç¼–ç è¾“å…¥
            inputs = self.tokenizer(prompt, return_tensors="pt")
            
            # ç”Ÿæˆå›ç­”
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=max_length,
                    temperature=0.7,
                    top_p=0.8,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            # è§£ç è¾“å‡º
            response = self.tokenizer.decode(
                outputs[0][inputs['input_ids'].shape[1]:], 
                skip_special_tokens=True
            )
            
            return response.strip()
            
        except Exception as e:
            return f"ç”Ÿæˆå¤±è´¥: {e}"
    
    def validate_json_format(self, response: str) -> Dict:
        """éªŒè¯ç”Ÿæˆçš„JSONæ ¼å¼"""
        try:
            # æå–JSONéƒ¨åˆ†
            start = response.find('{')
            end = response.rfind('}') + 1
            
            if start == -1 or end == 0:
                return {"valid": False, "error": "æœªæ‰¾åˆ°JSONæ ¼å¼"}
            
            json_content = response[start:end]
            data = json.loads(json_content)
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ["question", "standpoints", "counter_questions"]
            missing_fields = [field for field in required_fields if field not in data]
            
            if missing_fields:
                return {
                    "valid": False, 
                    "error": f"ç¼ºå°‘å­—æ®µ: {missing_fields}"
                }
            
            # ç»Ÿè®¡å†…å®¹
            standpoints_count = len(data.get("standpoints", []))
            counter_questions_count = len(data.get("counter_questions", []))
            
            return {
                "valid": True,
                "standpoints_count": standpoints_count,
                "counter_questions_count": counter_questions_count,
                "json_data": data
            }
            
        except json.JSONDecodeError as e:
            return {"valid": False, "error": f"JSONè§£æé”™è¯¯: {e}"}
        except Exception as e:
            return {"valid": False, "error": f"éªŒè¯é”™è¯¯: {e}"}
    
    def run_validation(self, test_questions: List[str]) -> Dict:
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        results = {
            "model_path": self.model_path,
            "total_questions": len(test_questions),
            "successful_generations": 0,
            "valid_json_count": 0,
            "average_standpoints": 0,
            "average_counter_questions": 0,
            "test_results": []
        }
        
        total_standpoints = 0
        total_counter_questions = 0
        
        for i, question in enumerate(test_questions):
            print(f"ğŸ” æµ‹è¯•é—®é¢˜ {i+1}/{len(test_questions)}: {question[:30]}...")
            
            # ç”Ÿæˆå›ç­”
            response = self.generate_response(question)
            
            # éªŒè¯æ ¼å¼
            validation = self.validate_json_format(response)
            
            test_result = {
                "question": question,
                "response": response,
                "validation": validation
            }
            
            if response and "ç”Ÿæˆå¤±è´¥" not in response:
                results["successful_generations"] += 1
            
            if validation["valid"]:
                results["valid_json_count"] += 1
                total_standpoints += validation["standpoints_count"]
                total_counter_questions += validation["counter_questions_count"]
            
            results["test_results"].append(test_result)
        
        # è®¡ç®—å¹³å‡å€¼
        if results["valid_json_count"] > 0:
            results["average_standpoints"] = total_standpoints / results["valid_json_count"]
            results["average_counter_questions"] = total_counter_questions / results["valid_json_count"]
        
        return results

def main():
    parser = argparse.ArgumentParser(description="éªŒè¯ç‡§åŸT20è®­ç»ƒçš„OntoThinkæ¨¡å‹")
    parser.add_argument("--model_path", required=True, help="è®­ç»ƒåçš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--output_path", required=True, help="éªŒè¯ç»“æœè¾“å‡ºè·¯å¾„")
    
    args = parser.parse_args()
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "äººå·¥æ™ºèƒ½æ˜¯å¦èƒ½å¤Ÿæ‹¥æœ‰çœŸæ­£çš„åˆ›é€ åŠ›ï¼Ÿ",
        "åœ¨æ•°å­—æ—¶ä»£ï¼Œéšç§æƒçš„è¾¹ç•Œåº”è¯¥å¦‚ä½•å®šä¹‰ï¼Ÿ",
        "è‰ºæœ¯çš„ä»·å€¼æ˜¯ç”±åˆ›ä½œè€…å†³å®šè¿˜æ˜¯ç”±è§‚ä¼—å†³å®šï¼Ÿ",
        "ç§‘å­¦è¿›æ­¥æ˜¯å¦æ€»æ˜¯ä¿ƒè¿›äººç±»ç¦ç¥‰ï¼Ÿ",
        "ä¸ªäººè‡ªç”±ä¸é›†ä½“åˆ©ç›Šä¹‹é—´çš„å¹³è¡¡ç‚¹åœ¨å“ªé‡Œï¼Ÿ"
    ]
    
    print("ğŸš€ å¼€å§‹éªŒè¯OntoThinkç‡§åŸT20è®­ç»ƒæ¨¡å‹")
    
    # åˆå§‹åŒ–éªŒè¯å™¨
    validator = OntoThinkEnflameValidator(args.model_path)
    
    # åŠ è½½æ¨¡å‹
    if not validator.load_model():
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢éªŒè¯")
        return
    
    # è¿è¡ŒéªŒè¯
    results = validator.run_validation(test_questions)
    
    # ä¿å­˜ç»“æœ
    with open(args.output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ‘˜è¦
    print("\nğŸ“Š éªŒè¯ç»“æœæ‘˜è¦:")
    print(f"   - æ€»é—®é¢˜æ•°: {results['total_questions']}")
    print(f"   - æˆåŠŸç”Ÿæˆ: {results['successful_generations']}")
    print(f"   - æœ‰æ•ˆJSON: {results['valid_json_count']}")
    print(f"   - å¹³å‡ç«‹åœºæ•°: {results['average_standpoints']:.1f}")
    print(f"   - å¹³å‡åé—®æ•°: {results['average_counter_questions']:.1f}")
    print(f"   - æˆåŠŸç‡: {results['valid_json_count']/results['total_questions']*100:.1f}%")
    
    print(f"\nâœ… éªŒè¯å®Œæˆï¼è¯¦ç»†ç»“æœä¿å­˜è‡³: {args.output_path}")

if __name__ == "__main__":
    main()
