#!/bin/bash

echo "ğŸš€ ChatGLM3-6B å¢å¼ºç‰ˆä¸‹è½½å™¨"
echo "é€‚ç”¨äºç‡§åŸT20ç¯å¢ƒ - åŒ…å«å®Œæ•´æ€§éªŒè¯"
echo "======================================"

# æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ONTOTHINK_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
MODEL_DIR="$ONTOTHINK_ROOT/enflame_training/models/THUDM/chatglm3-6b"

echo "ğŸ“ é¡¹ç›®æ ¹ç›®å½•: $ONTOTHINK_ROOT"
echo "ğŸ“ ç›®æ ‡ç›®å½•: $MODEL_DIR"
echo

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p "$(dirname "$MODEL_DIR")"

# å¦‚æœç›®å½•å­˜åœ¨ä¸”ä¸ä¸ºç©ºï¼Œå…ˆæ£€æŸ¥æ˜¯å¦å®Œæ•´
if [ -d "$MODEL_DIR" ] && [ "$(ls -A "$MODEL_DIR" 2>/dev/null)" ]; then
    echo "ğŸ“‹ æ£€æŸ¥ç°æœ‰æ¨¡å‹æ–‡ä»¶..."
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    missing_files=()
    required_files=("config.json" "tokenizer.model" "tokenizer_config.json" "modeling_chatglm.py")
    
    for file in "${required_files[@]}"; do
        if [ ! -f "$MODEL_DIR/$file" ]; then
            missing_files+=("$file")
        fi
    done
    
    # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶
    if [ ! -f "$MODEL_DIR/pytorch_model.bin.index.json" ] && [ ! -f "$MODEL_DIR/model.safetensors.index.json" ]; then
        missing_files+=("æ¨¡å‹æƒé‡ç´¢å¼•æ–‡ä»¶")
    fi
    
    # æ£€æŸ¥tokenizer.modelæ–‡ä»¶å¤§å°
    if [ -f "$MODEL_DIR/tokenizer.model" ]; then
        file_size=$(stat -c%s "$MODEL_DIR/tokenizer.model" 2>/dev/null || stat -f%z "$MODEL_DIR/tokenizer.model" 2>/dev/null)
        if [ "$file_size" -lt 1000000 ]; then
            missing_files+=("tokenizer.model (æ–‡ä»¶æŸå)")
        fi
    fi
    
    if [ ${#missing_files[@]} -eq 0 ]; then
        echo "âœ… ç°æœ‰æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½"
        
        # éªŒè¯tokenizerå®Œæ•´æ€§
        echo "ğŸ” éªŒè¯tokenizerå®Œæ•´æ€§..."
        python3 -c "
import sentencepiece as spm
try:
    sp = spm.SentencePieceProcessor()
    sp.load('$MODEL_DIR/tokenizer.model')
    print('âœ… tokenizeréªŒè¯é€šè¿‡')
except Exception as e:
    print(f'âŒ tokenizeréªŒè¯å¤±è´¥: {e}')
    exit(1)
" 2>/dev/null
        
        if [ $? -eq 0 ]; then
            echo "ğŸ‰ æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸”æœ‰æ•ˆï¼"
            exit 0
        else
            echo "âš ï¸  tokenizeréªŒè¯å¤±è´¥ï¼Œéœ€è¦é‡æ–°ä¸‹è½½"
        fi
    else
        echo "âš ï¸  å‘ç°ç¼ºå¤±æ–‡ä»¶: ${missing_files[*]}"
        echo "ğŸ”„ éœ€è¦é‡æ–°ä¸‹è½½å®Œæ•´æ¨¡å‹"
    fi
    
    # æ¸…ç†ä¸å®Œæ•´çš„ä¸‹è½½
    echo "ğŸ§¹ æ¸…ç†ä¸å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶..."
    rm -rf "$MODEL_DIR"
fi

echo "ğŸ“¥ å¼€å§‹ä¸‹è½½ChatGLM3-6Bæ¨¡å‹..."

# ä¸‹è½½æ–¹æ³•å‡½æ•°
download_with_modelscope() {
    echo "ğŸ”„ æ–¹æ³•1: ä½¿ç”¨ModelScopeé•œåƒ..."
    cd "$(dirname "$MODEL_DIR")"
    
    # ä½¿ç”¨git cloneä¸‹è½½
    if command -v git >/dev/null 2>&1; then
        git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git chatglm3-6b
        return $?
    else
        echo "âŒ gitå‘½ä»¤ä¸å¯ç”¨"
        return 1
    fi
}

download_with_huggingface() {
    echo "ğŸ”„ æ–¹æ³•2: ä½¿ç”¨Hugging Faceå®˜æ–¹æº..."
    cd "$(dirname "$MODEL_DIR")"
    
    if command -v git >/dev/null 2>&1; then
        # è®¾ç½®git lfs
        git lfs install 2>/dev/null || true
        git clone https://huggingface.co/THUDM/chatglm3-6b chatglm3-6b
        return $?
    else
        echo "âŒ gitå‘½ä»¤ä¸å¯ç”¨"
        return 1
    fi
}

download_with_python() {
    echo "ğŸ”„ æ–¹æ³•3: ä½¿ç”¨Pythonä¸‹è½½..."
    python3 << 'EOF'
import os
from huggingface_hub import snapshot_download

try:
    model_dir = os.environ.get('MODEL_DIR')
    snapshot_download(
        repo_id="THUDM/chatglm3-6b",
        local_dir=model_dir,
        local_dir_use_symlinks=False
    )
    print("âœ… Pythonä¸‹è½½æˆåŠŸ")
except Exception as e:
    print(f"âŒ Pythonä¸‹è½½å¤±è´¥: {e}")
    exit(1)
EOF
    return $?
}

# éªŒè¯ä¸‹è½½å®Œæ•´æ€§
verify_download() {
    echo "ğŸ” éªŒè¯ä¸‹è½½å®Œæ•´æ€§..."
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files=("config.json" "tokenizer.model" "tokenizer_config.json" "modeling_chatglm.py")
    for file in "${required_files[@]}"; do
        if [ ! -f "$MODEL_DIR/$file" ]; then
            echo "âŒ ç¼ºå¤±æ–‡ä»¶: $file"
            return 1
        fi
    done
    
    # æ£€æŸ¥æ¨¡å‹æƒé‡
    if [ ! -f "$MODEL_DIR/pytorch_model.bin.index.json" ] && [ ! -f "$MODEL_DIR/model.safetensors.index.json" ]; then
        echo "âŒ ç¼ºå¤±æ¨¡å‹æƒé‡ç´¢å¼•æ–‡ä»¶"
        return 1
    fi
    
    # éªŒè¯tokenizer.modelå¤§å°
    if [ -f "$MODEL_DIR/tokenizer.model" ]; then
        file_size=$(stat -c%s "$MODEL_DIR/tokenizer.model" 2>/dev/null || stat -f%z "$MODEL_DIR/tokenizer.model" 2>/dev/null)
        if [ "$file_size" -lt 1000000 ]; then
            echo "âŒ tokenizer.modelæ–‡ä»¶è¿‡å°ï¼Œå¯èƒ½æŸå"
            return 1
        fi
        echo "âœ… tokenizer.modelå¤§å°: ${file_size} bytes"
    fi
    
    # éªŒè¯tokenizeråŠŸèƒ½
    echo "ğŸ” éªŒè¯tokenizeråŠŸèƒ½..."
    python3 -c "
import sentencepiece as spm
try:
    sp = spm.SentencePieceProcessor()
    sp.load('$MODEL_DIR/tokenizer.model')
    # æµ‹è¯•ç¼–ç è§£ç 
    test_text = 'ä½ å¥½ï¼Œä¸–ç•Œï¼'
    tokens = sp.encode(test_text)
    decoded = sp.decode(tokens)
    print(f'âœ… tokenizeråŠŸèƒ½æµ‹è¯•é€šè¿‡: \"{test_text}\" -> {len(tokens)} tokens')
except Exception as e:
    print(f'âŒ tokenizeråŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}')
    exit(1)
" 2>/dev/null
    
    return $?
}

# å°è¯•ä¸åŒçš„ä¸‹è½½æ–¹æ³•
success=false
methods=("download_with_modelscope" "download_with_huggingface" "download_with_python")

for method in "${methods[@]}"; do
    echo
    $method
    if [ $? -eq 0 ]; then
        # éªŒè¯ä¸‹è½½
        if verify_download; then
            echo "âœ… ä¸‹è½½å¹¶éªŒè¯æˆåŠŸï¼"
            success=true
            break
        else
            echo "âŒ ä¸‹è½½éªŒè¯å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ç§æ–¹æ³•"
            rm -rf "$MODEL_DIR" 2>/dev/null || true
        fi
    else
        echo "âŒ ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ç§æ–¹æ³•"
        rm -rf "$MODEL_DIR" 2>/dev/null || true
    fi
done

if [ "$success" = true ]; then
    echo
    echo "ğŸ‰ ChatGLM3-6Bä¸‹è½½å®Œæˆï¼"
    echo
    echo "ğŸ“‹ ä¸‹ä¸€æ­¥:"
    echo "cd $ONTOTHINK_ROOT"
    echo "python3 enflame_training/scripts/train_ontothink_enflame.py --step full"
    echo
    echo "ğŸ“Š æ¨¡å‹æ–‡ä»¶ä¿¡æ¯:"
    ls -la "$MODEL_DIR/" | head -20
else
    echo
    echo "âŒ æ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥äº†"
    echo "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶"
    echo
    echo "ğŸ’¡ æ‰‹åŠ¨ä¸‹è½½æ–¹æ³•:"
    echo "1. è®¿é—®: https://www.modelscope.cn/ZhipuAI/chatglm3-6b"
    echo "2. æˆ–è®¿é—®: https://huggingface.co/THUDM/chatglm3-6b"
    echo "3. ä¸‹è½½åˆ°: $MODEL_DIR"
    exit 1
fi
