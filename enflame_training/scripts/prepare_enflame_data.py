#!/usr/bin/env python3
"""
OntoThinkæ•°æ®æ ¼å¼é€‚é…ç‡§åŸT20è®­ç»ƒ
å°†OntoThinkæ•°æ®è½¬æ¢ä¸ºç‡§åŸChatGLM3è®­ç»ƒæ‰€éœ€çš„æ ¼å¼
"""

import json
import argparse
from pathlib import Path
from typing import List, Dict, Any

def convert_to_enflame_format(ontothink_data: List[Dict]) -> List[Dict]:
    """
    å°†OntoThinkè®­ç»ƒæ•°æ®è½¬æ¢ä¸ºç‡§åŸChatGLM3æ‰€éœ€çš„å¤šè½®å¯¹è¯æ ¼å¼
    
    ç‡§åŸChatGLM3æœŸæœ›çš„æ•°æ®æ ¼å¼:
    {
        "conversations": [
            {
                "from": "human", 
                "value": "ç”¨æˆ·è¾“å…¥"
            },
            {
                "from": "gpt", 
                "value": "åŠ©æ‰‹å›å¤"
            }
        ]
    }
    """
    enflame_data = []
    
    for item in ontothink_data:
        instruction = item.get("instruction", "")
        input_text = item.get("input", "")
        output = item.get("output", "")
        category = item.get("category", "")
        
        # æ„å»ºç”¨æˆ·è¾“å…¥
        if input_text:
            user_input = f"{instruction}\n\n{input_text}"
        else:
            user_input = instruction
        
        # æ·»åŠ OntoThinkç³»ç»Ÿèº«ä»½
        system_prompt = "ä½ æ˜¯OntoThinkä¸“ä¸šæ€è¾¨åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå“²å­¦é—®é¢˜å¹¶ç”Ÿæˆå¤šç»´åº¦æ€è¾¨å›¾è°±ã€‚"
        user_input = f"{system_prompt}\n\n{user_input}"
        
        # æ„å»ºå¯¹è¯æ ¼å¼
        conversation = {
            "conversations": [
                {
                    "from": "human",
                    "value": user_input
                },
                {
                    "from": "gpt", 
                    "value": output
                }
            ]
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        if category:
            conversation["category"] = category
            
        enflame_data.append(conversation)
    
    return enflame_data

def create_summary_format_data(ontothink_data: List[Dict]) -> List[Dict]:
    """
    åˆ›å»ºæ‘˜è¦æ ¼å¼çš„æ•°æ®ï¼ˆé€‚é…ç‡§åŸçš„summaryè®­ç»ƒè„šæœ¬ï¼‰
    """
    summary_data = []
    
    for item in ontothink_data:
        instruction = item.get("instruction", "")
        input_text = item.get("input", "")
        output = item.get("output", "")
        
        # å°†instructionä½œä¸ºcontentï¼Œoutputä½œä¸ºsummary
        if input_text:
            content = f"{instruction} {input_text}"
        else:
            content = instruction
            
        summary_item = {
            "content": content,
            "summary": output
        }
        
        summary_data.append(summary_item)
    
    return summary_data

def split_data_for_enflame(data: List[Dict], train_ratio: float = 0.8, val_ratio: float = 0.1):
    """
    æŒ‰ç‡§åŸè¦æ±‚åˆ†å‰²æ•°æ®é›†
    """
    total_size = len(data)
    train_size = int(total_size * train_ratio)
    val_size = int(total_size * val_ratio)
    
    train_data = data[:train_size]
    val_data = data[train_size:train_size + val_size]
    test_data = data[train_size + val_size:]
    
    return train_data, val_data, test_data

def save_for_enflame_training(data: List[Dict], output_dir: Path, format_type: str = "multiturn"):
    """
    ä¿å­˜ä¸ºç‡§åŸè®­ç»ƒæ‰€éœ€çš„æ ¼å¼
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ†å‰²æ•°æ®
    train_data, val_data, test_data = split_data_for_enflame(data)
    
    if format_type == "multiturn":
        # å¤šè½®å¯¹è¯æ ¼å¼ (JSONL)
        datasets = {
            "train": train_data,
            "dev": val_data,
            "test": test_data
        }
        
        for split_name, split_data in datasets.items():
            output_file = output_dir / f"{split_name}.jsonl"
            with open(output_file, 'w', encoding='utf-8') as f:
                for item in split_data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            print(f"ğŸ’¾ ä¿å­˜ {split_name} æ•°æ®: {len(split_data)} æ¡ -> {output_file}")
    
    elif format_type == "summary":
        # æ‘˜è¦æ ¼å¼ (JSONL)
        summary_train = create_summary_format_data(train_data)
        summary_val = create_summary_format_data(val_data)
        
        train_file = output_dir / "train.jsonl"
        val_file = output_dir / "dev.jsonl"
        
        with open(train_file, 'w', encoding='utf-8') as f:
            for item in summary_train:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        with open(val_file, 'w', encoding='utf-8') as f:
            for item in summary_val:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ ä¿å­˜æ‘˜è¦æ ¼å¼è®­ç»ƒæ•°æ®: {len(summary_train)} æ¡ -> {train_file}")
        print(f"ğŸ’¾ ä¿å­˜æ‘˜è¦æ ¼å¼éªŒè¯æ•°æ®: {len(summary_val)} æ¡ -> {val_file}")

def load_ontothink_data(data_dir: str) -> List[Dict]:
    """åŠ è½½OntoThinkåŸå§‹è®­ç»ƒæ•°æ®"""
    all_data = []
    
    for file_name in ["train.jsonl", "val.jsonl", "test.jsonl"]:
        file_path = Path(data_dir) / file_name
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    all_data.append(json.loads(line))
    
    print(f"ğŸ“Š åŠ è½½OntoThinkæ•°æ®: {len(all_data)} æ¡")
    return all_data

def main():
    parser = argparse.ArgumentParser(description="å‡†å¤‡ç‡§åŸT20 ChatGLM3è®­ç»ƒæ•°æ®")
    parser.add_argument("--input_dir", required=True, help="OntoThinkæ•°æ®ç›®å½•")
    parser.add_argument("--output_dir", required=True, help="ç‡§åŸæ ¼å¼è¾“å‡ºç›®å½•")
    parser.add_argument("--format", choices=["multiturn", "summary"], default="multiturn", 
                       help="æ•°æ®æ ¼å¼: multiturn(å¤šè½®å¯¹è¯) æˆ– summary(æ‘˜è¦)")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹å‡†å¤‡ç‡§åŸT20è®­ç»ƒæ•°æ®...")
    
    # åŠ è½½OntoThinkæ•°æ®
    ontothink_data = load_ontothink_data(args.input_dir)
    
    if not ontothink_data:
        print("âŒ æœªæ‰¾åˆ°OntoThinkæ•°æ®")
        return
    
    # è½¬æ¢ä¸ºç‡§åŸæ ¼å¼
    if args.format == "multiturn":
        enflame_data = convert_to_enflame_format(ontothink_data)
    else:
        enflame_data = ontothink_data  # summaryæ ¼å¼åœ¨ä¿å­˜æ—¶è½¬æ¢
    
    # ä¿å­˜ç‡§åŸæ ¼å¼æ•°æ®
    save_for_enflame_training(enflame_data, Path(args.output_dir), args.format)
    
    print(f"âœ… ç‡§åŸT20æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“ æ•°æ®æ ¼å¼: {args.format}")

if __name__ == "__main__":
    main()
