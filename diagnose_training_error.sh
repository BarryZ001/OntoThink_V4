#!/bin/bash
# è®­ç»ƒé”™è¯¯è¯Šæ–­è„šæœ¬ - å½»åº•åˆ†æé—®é¢˜æ ¹æº
# é€‚ç”¨äºç‡§åŸT20ç¯å¢ƒ

set -e

echo "ğŸ” OntoThink è®­ç»ƒé”™è¯¯è¯Šæ–­å·¥å…·"
echo "========================================"

# è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ONTOTHINK_ROOT="$SCRIPT_DIR"
MODEL_DIR="${ONTOTHINK_ROOT}/enflame_training/models/THUDM/chatglm3-6b"

echo "ğŸ“ é¡¹ç›®æ ¹ç›®å½•: $ONTOTHINK_ROOT"
echo "ğŸ“ æ¨¡å‹ç›®å½•: $MODEL_DIR"

# 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶çŠ¶æ€
echo ""
echo "ğŸ” 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶çŠ¶æ€"
echo "----------------------------------------"

if [ -d "$MODEL_DIR" ]; then
    cd "$MODEL_DIR"
    echo "ğŸ“ æ¨¡å‹ç›®å½•å­˜åœ¨"
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    echo ""
    echo "ğŸ“‹ å…³é”®æ–‡ä»¶æ£€æŸ¥:"
    
    # tokenizer.model
    if [ -f "tokenizer.model" ]; then
        size=$(stat -c%s "tokenizer.model")
        echo "tokenizer.model: $size bytes"
        
        if [ "$size" -gt 1000000 ]; then
            echo "âœ… tokenizer.model å¤§å°æ­£å¸¸"
            
            # æµ‹è¯•tokenizeråŠŸèƒ½
            echo "ğŸ§ª æµ‹è¯•tokenizeråŠŸèƒ½..."
            python3 -c "
import sentencepiece as smp
try:
    sp = smp.SentencePieceProcessor()
    sp.load('tokenizer.model')
    print('âœ… tokenizeråŠ è½½æˆåŠŸ')
    
    # ç¼–ç æµ‹è¯•
    tokens = sp.encode('æµ‹è¯•æ–‡æœ¬')
    decoded = sp.decode(tokens)
    print(f'âœ… ç¼–ç è§£ç æ­£å¸¸: {len(tokens)} tokens')
except Exception as e:
    print(f'âŒ tokenizeråŠŸèƒ½å¼‚å¸¸: {e}')
    exit(1)
" 2>/dev/null
            
            if [ $? -eq 0 ]; then
                echo "âœ… tokenizeråŠŸèƒ½æ­£å¸¸"
            else
                echo "âŒ tokenizeråŠŸèƒ½å¼‚å¸¸"
            fi
        else
            echo "âŒ tokenizer.modelè¿‡å°ï¼Œå¯èƒ½æŸå"
        fi
    else
        echo "âŒ tokenizer.modelä¸å­˜åœ¨"
    fi
    
    # æƒé‡æ–‡ä»¶
    echo ""
    echo "ğŸ“‹ æƒé‡æ–‡ä»¶æ£€æŸ¥:"
    weight_count=0
    for i in {1..7}; do
        safetensor_file="model-0000${i}-of-00007.safetensors"
        pytorch_file="pytorch_model-0000${i}-of-00007.bin"
        
        if [ -f "$safetensor_file" ]; then
            size=$(stat -c%s "$safetensor_file")
            if [ "$size" -gt 100000000 ]; then
                echo "âœ… $safetensor_file: $(echo $size | awk '{printf "%.1f MB", $1/1024/1024}')"
                ((weight_count++))
            else
                echo "âŒ $safetensor_file: $size bytes (ç–‘ä¼¼LFSæŒ‡é’ˆ)"
            fi
        elif [ -f "$pytorch_file" ]; then
            size=$(stat -c%s "$pytorch_file")
            if [ "$size" -gt 100000000 ]; then
                echo "âœ… $pytorch_file: $(echo $size | awk '{printf "%.1f MB", $1/1024/1024}')"
                ((weight_count++))
            else
                echo "âŒ $pytorch_file: $size bytes (ç–‘ä¼¼LFSæŒ‡é’ˆ)"
            fi
        else
            echo "âŒ æƒé‡æ–‡ä»¶ $i ç¼ºå¤±"
        fi
    done
    
    echo "ğŸ“Š æƒé‡æ–‡ä»¶ç»Ÿè®¡: $weight_count/7"
    
    # é…ç½®æ–‡ä»¶
    echo ""
    echo "ğŸ“‹ é…ç½®æ–‡ä»¶æ£€æŸ¥:"
    config_files=("config.json" "tokenizer_config.json" "modeling_chatglm.py" "tokenization_chatglm.py")
    for file in "${config_files[@]}"; do
        if [ -f "$file" ]; then
            echo "âœ… $file"
        else
            echo "âŒ $file ç¼ºå¤±"
        fi
    done
    
else
    echo "âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: $MODEL_DIR"
fi

# 2. æ£€æŸ¥Pythonç¯å¢ƒ
echo ""
echo "ğŸ” 2. æ£€æŸ¥Pythonç¯å¢ƒ"
echo "----------------------------------------"

echo "ğŸ Pythonç‰ˆæœ¬:"
python3 --version

echo ""
echo "ğŸ“¦ å…³é”®åŒ…æ£€æŸ¥:"
python3 -c "
packages = [
    'torch', 'transformers', 'accelerate', 'peft', 
    'sentencepiece', 'ptex', 'collie_lm', 'deepspeed'
]

for pkg in packages:
    try:
        module = __import__(pkg)
        version = getattr(module, '__version__', 'unknown')
        print(f'âœ… {pkg}: {version}')
    except ImportError:
        print(f'âŒ {pkg}: æœªå®‰è£…')
    except Exception as e:
        print(f'âš ï¸  {pkg}: å¯¼å…¥å¼‚å¸¸ - {e}')
"

# 3. æ£€æŸ¥ç‡§åŸç¯å¢ƒ
echo ""
echo "ğŸ” 3. æ£€æŸ¥ç‡§åŸT20ç¯å¢ƒ"
echo "----------------------------------------"

# æ£€æŸ¥ç‡§åŸå·¥å…·åŒ…
ENFLAME_PATHS=(
    "${ONTOTHINK_ROOT}/FromEnflame/ai_development_toolkit/distributed"
    "/installer/topsrider_extracted/TopsRider_installer/ai_development_toolkit/distributed"
)

FOUND_ENFLAME=false
for path in "${ENFLAME_PATHS[@]}"; do
    if [ -d "$path" ]; then
        echo "âœ… ç‡§åŸå·¥å…·åŒ…: $path"
        FOUND_ENFLAME=true
        
        # æ£€æŸ¥LLMè„šæœ¬
        if [ -d "$path/llm_scripts_1.0.40/finetuning/chatglm3" ]; then
            echo "âœ… ChatGLM3è„šæœ¬ç›®å½•å­˜åœ¨"
            
            script_file="$path/llm_scripts_1.0.40/finetuning/chatglm3/finetune_chatglm3_for_multiturn.py"
            if [ -f "$script_file" ]; then
                echo "âœ… è®­ç»ƒè„šæœ¬å­˜åœ¨"
            else
                echo "âŒ è®­ç»ƒè„šæœ¬ç¼ºå¤±: $script_file"
            fi
        else
            echo "âŒ ChatGLM3è„šæœ¬ç›®å½•ç¼ºå¤±"
        fi
        break
    fi
done

if [ "$FOUND_ENFLAME" = false ]; then
    echo "âŒ æœªæ‰¾åˆ°ç‡§åŸå·¥å…·åŒ…"
fi

# 4. æ£€æŸ¥è®­ç»ƒæ•°æ®
echo ""
echo "ğŸ” 4. æ£€æŸ¥è®­ç»ƒæ•°æ®"
echo "----------------------------------------"

DATA_DIR="${ONTOTHINK_ROOT}/enflame_training/datasets/ontothink_multiturn"
if [ -d "$DATA_DIR" ]; then
    echo "âœ… æ•°æ®ç›®å½•å­˜åœ¨: $DATA_DIR"
    
    if [ -f "$DATA_DIR/train.jsonl" ]; then
        line_count=$(wc -l < "$DATA_DIR/train.jsonl")
        echo "âœ… è®­ç»ƒæ•°æ®: $line_count è¡Œ"
    else
        echo "âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ç¼ºå¤±"
    fi
else
    echo "âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨"
fi

# 5. è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•
echo ""
echo "ğŸ” 5. è¿è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•"
echo "----------------------------------------"

if [ -f "$MODEL_DIR/tokenizer.model" ] && [ -f "$MODEL_DIR/config.json" ]; then
    echo "ğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½..."
    
    cd "$MODEL_DIR"
    python3 -c "
import sys
import os
sys.path.append('.')

try:
    from transformers import AutoTokenizer, AutoModel
    
    print('ğŸ“¥ åŠ è½½tokenizer...')
    tokenizer = AutoTokenizer.from_pretrained('.', trust_remote_code=True)
    print('âœ… TokenizeråŠ è½½æˆåŠŸ')
    
    print('ğŸ“¥ åŠ è½½æ¨¡å‹é…ç½®...')
    # åªåŠ è½½é…ç½®ï¼Œä¸åŠ è½½æƒé‡
    from transformers import AutoConfig
    config = AutoConfig.from_pretrained('.', trust_remote_code=True)
    print('âœ… æ¨¡å‹é…ç½®åŠ è½½æˆåŠŸ')
    
    print('ğŸ§ª æµ‹è¯•tokenizerç¼–ç ...')
    text = 'ChatGLM3æµ‹è¯•æ–‡æœ¬'
    tokens = tokenizer.encode(text)
    decoded = tokenizer.decode(tokens)
    print(f'âœ… ç¼–ç æµ‹è¯•é€šè¿‡: {len(tokens)} tokens')
    print(f'   åŸæ–‡: {text}')
    print(f'   è§£ç : {decoded}')
    
except Exception as e:
    print(f'âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)
"
    
    if [ $? -eq 0 ]; then
        echo "âœ… æ¨¡å‹åŠ è½½æµ‹è¯•é€šè¿‡"
    else
        echo "âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥"
    fi
else
    echo "âš ï¸  è·³è¿‡æ¨¡å‹åŠ è½½æµ‹è¯•ï¼ˆæ–‡ä»¶ç¼ºå¤±ï¼‰"
fi

# 6. ç”Ÿæˆä¿®å¤å»ºè®®
echo ""
echo "ğŸ”§ 6. ä¿®å¤å»ºè®®"
echo "----------------------------------------"

echo "åŸºäºè¯Šæ–­ç»“æœï¼Œå»ºè®®æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š"
echo ""

# æ£€æŸ¥ä¸»è¦é—®é¢˜
if [ ! -f "$MODEL_DIR/tokenizer.model" ] || [ "$(stat -c%s "$MODEL_DIR/tokenizer.model" 2>/dev/null || echo 0)" -lt 1000000 ]; then
    echo "ğŸ”´ ä¸»è¦é—®é¢˜: tokenizer.modelç¼ºå¤±æˆ–æŸå"
    echo "   è§£å†³æ–¹æ¡ˆ:"
    echo "   1. åœ¨æœ¬åœ°Macä¸‹è½½å®Œæ•´æ¨¡å‹:"
    echo "      ./download_chatglm3_local.sh"
    echo "   2. ä¸Šä¼ åˆ°æœåŠ¡å™¨:"
    echo "      rsync -avz --progress -e 'ssh -p 60025' chatglm3-6b/ root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b/"
    echo ""
fi

if [ "$weight_count" -lt 7 ]; then
    echo "ğŸ”´ ä¸»è¦é—®é¢˜: æƒé‡æ–‡ä»¶ä¸å®Œæ•´ ($weight_count/7)"
    echo "   è§£å†³æ–¹æ¡ˆ: éœ€è¦é‡æ–°ä¸‹è½½å®Œæ•´æ¨¡å‹"
    echo ""
fi

echo "ğŸ”„ å¿«é€Ÿä¿®å¤å‘½ä»¤ï¼š"
echo "# 1. ä½¿ç”¨Git LFSä¿®å¤å·¥å…·"
echo "bash ${ONTOTHINK_ROOT}/fix_git_lfs_download.sh"
echo ""
echo "# 2. ä½¿ç”¨å®Œæ•´ä¿®å¤å·¥å…·" 
echo "bash ${ONTOTHINK_ROOT}/fix_chatglm3_complete.sh"
echo ""
echo "# 3. æ‰‹åŠ¨Pythonä¸‹è½½"
echo "python3 ${ONTOTHINK_ROOT}/enflame_training/scripts/manual_download_chatglm3.py"

echo ""
echo "========================================"
echo "ğŸ è¯Šæ–­å®Œæˆ"
echo ""
echo "ğŸ“‹ å¦‚éœ€è¯¦ç»†å¸®åŠ©ï¼Œè¯·æŸ¥çœ‹:"
echo "   - download_and_upload_chatglm3.md"
echo "   - fix_chatglm3_complete.sh"
echo "   - manual_download_chatglm3.py"
