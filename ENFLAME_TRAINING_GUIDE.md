# ğŸ”¥ ç‡§åŸT20å®˜æ–¹æ ‡å‡†è®­ç»ƒæŒ‡å—

åŸºäºç‡§åŸå®˜æ–¹æ–‡æ¡£å’Œllm_scriptsç¤ºä¾‹

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ç‡§åŸä¾èµ–ï¼ˆæœåŠ¡å™¨ä¸Šè¿è¡Œï¼‰

```bash
cd /workspace/code/OntoThink_V4
bash install_enflame_official.sh
```

### 2. è¿è¡Œç‡§åŸå®˜æ–¹æ ‡å‡†è®­ç»ƒï¼ˆæœåŠ¡å™¨ä¸Šè¿è¡Œï¼‰

```bash
cd /workspace/code/OntoThink_V4
bash train_ontothink_enflame_official.sh
```

## ğŸ“‹ å…³é”®ç‰¹æ€§

### ğŸ”§ ç‡§åŸT20ç¯å¢ƒå˜é‡
- `ENFLAME_ENABLE_EFP=true`: å¯ç”¨ç‡§åŸEFPåŠ é€Ÿ
- `ENFLAME_PT_ENABLE_HBM_INPLACE=true`: å¯ç”¨HBMåŸåœ°æ“ä½œ
- `ECCL_MAX_NCHANNELS=2`: ECCLé€šä¿¡é€šé“æ•°
- `ENFLAME_UMD_FLAGS="mem_alloc_retry_times=1"`: å†…å­˜åˆ†é…é‡è¯•

### ğŸš€ ç‡§åŸåˆ†å¸ƒå¼å¯åŠ¨
- ä½¿ç”¨ `python3.8 -u -m torch.distributed.launch`
- `--nproc_per_node=8`: 8å¡GCU
- `--standalone`: å•æœºæ¨¡å¼
- `--use_env`: ä½¿ç”¨ç¯å¢ƒå˜é‡

### ğŸ“¦ ç‡§åŸå®˜æ–¹ä¾èµ–
- ä½¿ç”¨ç‡§åŸå®˜æ–¹ `install_for_llm_scripts.sh`
- ç‡§åŸä¼˜åŒ–ç‰ˆæœ¬ï¼šptex, collie_lm, deepspeed, transformers, accelerate, peft

## ğŸ” é—®é¢˜æ’æŸ¥

å¦‚æœè®­ç»ƒä»ç„¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š

1. **GCUè®¾å¤‡çŠ¶æ€**:
   ```bash
   ls -la /dev/gcu*
   ```

2. **ç‡§åŸPythonåŒ…**:
   ```bash
   python3 -c "import ptex, collie_lm; print('ç‡§åŸåŒ…æ­£å¸¸')"
   ```

3. **ç‡§åŸtorch_gcu**:
   ```bash
   python3 -c "import torch; print('PyTorch:', torch.__version__)"
   ```

## ğŸ“š å‚è€ƒæ–‡æ¡£

- ç‡§åŸLLMå¾®è°ƒç”¨æˆ·æŒ‡å—: `FromEnflame/.../documents/Enflame_llm_finetuning_user_guide.md`
- ç‡§åŸå®˜æ–¹ç¤ºä¾‹: `FromEnflame/.../llm_scripts_1.0.40/finetuning/chatglm3/`
