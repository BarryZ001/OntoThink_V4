#!/bin/bash
# æœåŠ¡å™¨ç«¯æ¨¡å‹éªŒè¯è„šæœ¬
# éªŒè¯ä¸Šä¼ çš„ChatGLM3æ¨¡å‹æ˜¯å¦å®Œæ•´å¯ç”¨

set -e

echo "ğŸ” ChatGLM3 ä¸Šä¼ æ¨¡å‹éªŒè¯å·¥å…·"
echo "é€‚ç”¨äºç‡§åŸT20æœåŠ¡å™¨ç¯å¢ƒ"
echo "========================================"

# è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ONTOTHINK_ROOT="$SCRIPT_DIR"
MODEL_DIR="${ONTOTHINK_ROOT}/enflame_training/models/THUDM/chatglm3-6b"

echo "ğŸ“ é¡¹ç›®æ ¹ç›®å½•: $ONTOTHINK_ROOT"
echo "ğŸ“ æ¨¡å‹ç›®å½•: $MODEL_DIR"

if [ ! -d "$MODEL_DIR" ]; then
    echo "âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: $MODEL_DIR"
    echo ""
    echo "ğŸ’¡ è¯·å…ˆä¸Šä¼ æ¨¡å‹æ–‡ä»¶:"
    echo "   æ–¹æ³•1: rsyncä¸Šä¼ "
    echo "   æ–¹æ³•2: è§£å‹tar.gzæ–‡ä»¶"
    echo "   è¯¦è§: download_and_upload_chatglm3.md"
    exit 1
fi

cd "$MODEL_DIR"

echo ""
echo "ğŸ” 1. æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥"
echo "----------------------------------------"

# æ£€æŸ¥tokenizer
echo "ğŸ“‹ Tokenizeræ£€æŸ¥:"
if [ -f "tokenizer.model" ]; then
    size=$(stat -c%s "tokenizer.model")
    echo "tokenizer.model: $size bytes"
    
    if [ "$size" -gt 1000000 ]; then
        echo "âœ… tokenizer.model å¤§å°æ­£å¸¸"
        TOKENIZER_OK=true
    else
        echo "âŒ tokenizer.model è¿‡å°"
        TOKENIZER_OK=false
    fi
else
    echo "âŒ tokenizer.model ä¸å­˜åœ¨"
    TOKENIZER_OK=false
fi

# æ£€æŸ¥æƒé‡æ–‡ä»¶
echo ""
echo "ğŸ“‹ æƒé‡æ–‡ä»¶æ£€æŸ¥:"
WEIGHT_COUNT=0
TOTAL_SIZE=0

for i in {1..7}; do
    safetensor_file="model-0000${i}-of-00007.safetensors"
    pytorch_file="pytorch_model-0000${i}-of-00007.bin"
    
    if [ -f "$safetensor_file" ]; then
        size=$(stat -c%s "$safetensor_file")
        TOTAL_SIZE=$((TOTAL_SIZE + size))
        
        if [ "$size" -gt 100000000 ]; then
            size_mb=$(echo "$size" | awk '{printf "%.1f MB", $1/1024/1024}')
            echo "âœ… $safetensor_file: $size_mb"
            ((WEIGHT_COUNT++))
        else
            echo "âŒ $safetensor_file: $size bytes (ç–‘ä¼¼LFSæŒ‡é’ˆ)"
        fi
    elif [ -f "$pytorch_file" ]; then
        size=$(stat -c%s "$pytorch_file")
        TOTAL_SIZE=$((TOTAL_SIZE + size))
        
        if [ "$size" -gt 100000000 ]; then
            size_mb=$(echo "$size" | awk '{printf "%.1f MB", $1/1024/1024}')
            echo "âœ… $pytorch_file: $size_mb"
            ((WEIGHT_COUNT++))
        else
            echo "âŒ $pytorch_file: $size bytes (ç–‘ä¼¼LFSæŒ‡é’ˆ)"
        fi
    else
        echo "âŒ æƒé‡æ–‡ä»¶ $i ä¸å­˜åœ¨"
    fi
done

echo "ğŸ“Š æƒé‡æ–‡ä»¶ç»Ÿè®¡: $WEIGHT_COUNT/7"
total_gb=$(echo "$TOTAL_SIZE" | awk '{printf "%.2f GB", $1/1024/1024/1024}')
echo "ğŸ“Š æƒé‡æ–‡ä»¶æ€»å¤§å°: $total_gb"

WEIGHTS_OK=false
if [ "$WEIGHT_COUNT" -eq 7 ]; then
    WEIGHTS_OK=true
    echo "âœ… æƒé‡æ–‡ä»¶å®Œæ•´"
else
    echo "âŒ æƒé‡æ–‡ä»¶ä¸å®Œæ•´"
fi

# æ£€æŸ¥é…ç½®æ–‡ä»¶
echo ""
echo "ğŸ“‹ é…ç½®æ–‡ä»¶æ£€æŸ¥:"
config_files=(
    "config.json"
    "tokenizer_config.json" 
    "special_tokens_map.json"
    "modeling_chatglm.py"
    "tokenization_chatglm.py"
    "configuration_chatglm.py"
)

CONFIG_COUNT=0
for file in "${config_files[@]}"; do
    if [ -f "$file" ]; then
        echo "âœ… $file"
        ((CONFIG_COUNT++))
    else
        echo "âŒ $file ç¼ºå¤±"
    fi
done

echo "ğŸ“Š é…ç½®æ–‡ä»¶ç»Ÿè®¡: $CONFIG_COUNT/${#config_files[@]}"

# 2. åŠŸèƒ½æ€§æµ‹è¯•
echo ""
echo "ğŸ” 2. åŠŸèƒ½æ€§æµ‹è¯•"
echo "----------------------------------------"

if [ "$TOKENIZER_OK" = true ]; then
    echo "ğŸ§ª æµ‹è¯•sentencepiece tokenizer..."
    python3 -c "
import sentencepiece as smp
try:
    sp = smp.SentencePieceProcessor()
    sp.load('tokenizer.model')
    
    # ç¼–ç æµ‹è¯•
    test_texts = [
        'ä½ å¥½ï¼Œä¸–ç•Œï¼',
        'ChatGLM3æ˜¯ä¸€ä¸ªå¯¹è¯è¯­è¨€æ¨¡å‹',
        'Hello, how are you?',
        'äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¿…é€Ÿ'
    ]
    
    for text in test_texts:
        tokens = sp.encode(text)
        decoded = sp.decode(tokens)
        if decoded.strip() == text.strip():
            print(f'âœ… ç¼–ç è§£ç æ­£å¸¸: \"{text}\" ({len(tokens)} tokens)')
        else:
            print(f'âŒ ç¼–ç è§£ç å¼‚å¸¸: \"{text}\" -> \"{decoded}\"')
    
    print('âœ… SentencePiece tokenizeråŠŸèƒ½æ­£å¸¸')
    
except Exception as e:
    print(f'âŒ SentencePiece tokenizeræµ‹è¯•å¤±è´¥: {e}')
    exit(1)
" 2>/dev/null

    if [ $? -eq 0 ]; then
        echo "âœ… SentencePiece tokenizeræµ‹è¯•é€šè¿‡"
    else
        echo "âŒ SentencePiece tokenizeræµ‹è¯•å¤±è´¥"
    fi
    
    echo ""
    echo "ğŸ§ª æµ‹è¯•transformers tokenizer..."
    python3 -c "
import sys
import os
sys.path.append('.')

try:
    from transformers import AutoTokenizer
    
    print('ğŸ“¥ åŠ è½½tokenizer...')
    tokenizer = AutoTokenizer.from_pretrained('.', trust_remote_code=True)
    print('âœ… Transformers tokenizeråŠ è½½æˆåŠŸ')
    
    # ç¼–ç æµ‹è¯•
    test_texts = [
        'ä½ å¥½ï¼ŒChatGLM3ï¼',
        'How are you today?',
        'è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹ã€‚'
    ]
    
    for text in test_texts:
        tokens = tokenizer.encode(text)
        decoded = tokenizer.decode(tokens, skip_special_tokens=True)
        print(f'âœ… ç¼–ç è§£ç æµ‹è¯•: \"{text}\" ({len(tokens)} tokens)')
        if decoded.strip() != text.strip():
            print(f'   âš ï¸  è§£ç ç»“æœ: \"{decoded}\"')
    
    print('âœ… Transformers tokenizeråŠŸèƒ½æ­£å¸¸')
    
except Exception as e:
    print(f'âŒ Transformers tokenizeræµ‹è¯•å¤±è´¥: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)
" 2>/dev/null

    if [ $? -eq 0 ]; then
        echo "âœ… Transformers tokenizeræµ‹è¯•é€šè¿‡"
        TOKENIZER_FUNCTIONAL=true
    else
        echo "âŒ Transformers tokenizeræµ‹è¯•å¤±è´¥"
        TOKENIZER_FUNCTIONAL=false
    fi
else
    echo "âš ï¸  è·³è¿‡tokenizeråŠŸèƒ½æµ‹è¯•ï¼ˆæ–‡ä»¶é—®é¢˜ï¼‰"
    TOKENIZER_FUNCTIONAL=false
fi

# 3. æ¨¡å‹é…ç½®æµ‹è¯•
echo ""
echo "ğŸ” 3. æ¨¡å‹é…ç½®æµ‹è¯•"
echo "----------------------------------------"

if [ -f "config.json" ]; then
    echo "ğŸ§ª æµ‹è¯•æ¨¡å‹é…ç½®åŠ è½½..."
    python3 -c "
import sys
import os
sys.path.append('.')

try:
    from transformers import AutoConfig
    
    print('ğŸ“¥ åŠ è½½æ¨¡å‹é…ç½®...')
    config = AutoConfig.from_pretrained('.', trust_remote_code=True)
    
    print(f'âœ… æ¨¡å‹é…ç½®åŠ è½½æˆåŠŸ')
    print(f'   æ¨¡å‹ç±»å‹: {config.model_type}')
    print(f'   éšè—å±‚å¤§å°: {config.hidden_size}')
    print(f'   å±‚æ•°: {config.num_layers}')
    print(f'   æ³¨æ„åŠ›å¤´æ•°: {config.num_attention_heads}')
    print(f'   è¯æ±‡è¡¨å¤§å°: {config.vocab_size}')
    
except Exception as e:
    print(f'âŒ æ¨¡å‹é…ç½®åŠ è½½å¤±è´¥: {e}')
    sys.exit(1)
"

    if [ $? -eq 0 ]; then
        echo "âœ… æ¨¡å‹é…ç½®æµ‹è¯•é€šè¿‡"
        CONFIG_FUNCTIONAL=true
    else
        echo "âŒ æ¨¡å‹é…ç½®æµ‹è¯•å¤±è´¥"
        CONFIG_FUNCTIONAL=false
    fi
else
    echo "âš ï¸  è·³è¿‡æ¨¡å‹é…ç½®æµ‹è¯•ï¼ˆconfig.jsonç¼ºå¤±ï¼‰"
    CONFIG_FUNCTIONAL=false
fi

# 4. ç»¼åˆè¯„ä¼°
echo ""
echo "ğŸ” 4. ç»¼åˆè¯„ä¼°"
echo "========================================"

echo "ğŸ“Š æ£€æŸ¥ç»“æœæ±‡æ€»:"
echo "   Tokenizeræ–‡ä»¶: $([ "$TOKENIZER_OK" = true ] && echo "âœ… æ­£å¸¸" || echo "âŒ å¼‚å¸¸")"
echo "   æƒé‡æ–‡ä»¶: $([ "$WEIGHTS_OK" = true ] && echo "âœ… å®Œæ•´ ($WEIGHT_COUNT/7)" || echo "âŒ ä¸å®Œæ•´ ($WEIGHT_COUNT/7)")"
echo "   é…ç½®æ–‡ä»¶: $([ "$CONFIG_COUNT" -eq ${#config_files[@]} ] && echo "âœ… å®Œæ•´ ($CONFIG_COUNT/${#config_files[@]})" || echo "âŒ ä¸å®Œæ•´ ($CONFIG_COUNT/${#config_files[@]})")"
echo "   TokenizeråŠŸèƒ½: $([ "$TOKENIZER_FUNCTIONAL" = true ] && echo "âœ… æ­£å¸¸" || echo "âŒ å¼‚å¸¸")"
echo "   æ¨¡å‹é…ç½®: $([ "$CONFIG_FUNCTIONAL" = true ] && echo "âœ… æ­£å¸¸" || echo "âŒ å¼‚å¸¸")"

echo ""
if [ "$TOKENIZER_OK" = true ] && [ "$WEIGHTS_OK" = true ] && [ "$TOKENIZER_FUNCTIONAL" = true ] && [ "$CONFIG_FUNCTIONAL" = true ]; then
    echo "ğŸ‰ æ¨¡å‹éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ"
    echo ""
    echo "ğŸš€ ä¸‹ä¸€æ­¥ï¼šå¼€å§‹è®­ç»ƒ"
    echo "cd $ONTOTHINK_ROOT"
    echo "python3 enflame_training/scripts/train_ontothink_enflame.py --step full"
    
    exit 0
else
    echo "âŒ æ¨¡å‹éªŒè¯å¤±è´¥"
    echo ""
    echo "ğŸ”§ ä¿®å¤å»ºè®®:"
    
    if [ "$TOKENIZER_OK" = false ]; then
        echo "   1. Tokenizeræ–‡ä»¶é—®é¢˜ - é‡æ–°ä¸Šä¼ tokenizer.model"
    fi
    
    if [ "$WEIGHTS_OK" = false ]; then
        echo "   2. æƒé‡æ–‡ä»¶ä¸å®Œæ•´ - é‡æ–°ä¸Šä¼ å®Œæ•´æ¨¡å‹"
    fi
    
    if [ "$TOKENIZER_FUNCTIONAL" = false ]; then
        echo "   3. TokenizeråŠŸèƒ½å¼‚å¸¸ - æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–"
    fi
    
    if [ "$CONFIG_FUNCTIONAL" = false ]; then
        echo "   4. æ¨¡å‹é…ç½®å¼‚å¸¸ - é‡æ–°ä¸Šä¼ é…ç½®æ–‡ä»¶"
    fi
    
    echo ""
    echo "ğŸ’¡ å¿«é€Ÿä¿®å¤å‘½ä»¤:"
    echo "   bash $ONTOTHINK_ROOT/fix_chatglm3_complete.sh"
    echo "   python3 $ONTOTHINK_ROOT/enflame_training/scripts/manual_download_chatglm3.py"
    
    exit 1
fi
