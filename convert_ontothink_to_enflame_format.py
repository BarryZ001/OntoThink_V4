#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
OntoThinkæ•°æ®æ ¼å¼è½¬æ¢å™¨
å°†OntoThinkåŸå§‹æ ¼å¼è½¬æ¢ä¸ºç‡§åŸChatGLM3è¦æ±‚çš„conversationæ ¼å¼

åŸå§‹æ ¼å¼ï¼š
{"instruction": "...", "input": "...", "output": "...", "category": "..."}

ç‡§åŸæ ¼å¼ï¼š
{"conversation": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
"""

import json
import os
import sys
from typing import Dict, List, Any

def convert_ontothink_to_enflame(input_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    å°†å•æ¡OntoThinkæ•°æ®è½¬æ¢ä¸ºç‡§åŸChatGLM3æ ¼å¼
    
    Args:
        input_data: OntoThinkæ ¼å¼çš„æ•°æ®
        
    Returns:
        ç‡§åŸChatGLM3æ ¼å¼çš„æ•°æ®
    """
    instruction = input_data.get('instruction', '').strip()
    input_text = input_data.get('input', '').strip()
    output = input_data.get('output', '').strip()
    category = input_data.get('category', '')
    
    # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
    if input_text:
        # å¦‚æœæœ‰inputå­—æ®µï¼Œå°†å…¶ä¸instructionåˆå¹¶
        user_content = f"{instruction}\n\n{input_text}"
    else:
        # å¦‚æœæ²¡æœ‰inputå­—æ®µï¼Œç›´æ¥ä½¿ç”¨instruction
        user_content = instruction
    
    # æ„å»ºå¯¹è¯æ ¼å¼
    conversation = [
        {
            "role": "user",
            "content": user_content
        },
        {
            "role": "assistant", 
            "content": output
        }
    ]
    
    # ç‡§åŸæ ¼å¼
    result = {
        "conversation": conversation
    }
    
    # å¯é€‰ï¼šä¿ç•™ç±»åˆ«ä¿¡æ¯ä½œä¸ºå…ƒæ•°æ®
    if category:
        result["category"] = category
        
    return result

def convert_file(input_file: str, output_file: str) -> None:
    """
    è½¬æ¢æ•´ä¸ªæ–‡ä»¶
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ (OntoThink JSONLæ ¼å¼)
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (ç‡§åŸChatGLM3æ ¼å¼)
    """
    print(f"ğŸ”„ è½¬æ¢æ–‡ä»¶: {input_file} â†’ {output_file}")
    
    converted_count = 0
    error_count = 0
    
    with open(input_file, 'r', encoding='utf-8') as f_in, \
         open(output_file, 'w', encoding='utf-8') as f_out:
        
        for line_num, line in enumerate(f_in, 1):
            line = line.strip()
            if not line:
                continue
                
            try:
                # è§£æåŸå§‹æ•°æ®
                input_data = json.loads(line)
                
                # è½¬æ¢æ ¼å¼
                converted_data = convert_ontothink_to_enflame(input_data)
                
                # å†™å…¥è½¬æ¢åçš„æ•°æ®
                json.dump(converted_data, f_out, ensure_ascii=False)
                f_out.write('\n')
                
                converted_count += 1
                
                if converted_count % 100 == 0:
                    print(f"  å·²è½¬æ¢ {converted_count} æ¡æ•°æ®...")
                    
            except Exception as e:
                print(f"  âŒ ç¬¬{line_num}è¡Œè½¬æ¢å¤±è´¥: {e}")
                error_count += 1
                continue
    
    print(f"âœ… è½¬æ¢å®Œæˆ:")
    print(f"  - æˆåŠŸè½¬æ¢: {converted_count} æ¡")
    print(f"  - è½¬æ¢å¤±è´¥: {error_count} æ¡")
    print(f"  - è¾“å‡ºæ–‡ä»¶: {output_file}")

def preview_conversion(input_file: str, num_samples: int = 3) -> None:
    """
    é¢„è§ˆè½¬æ¢ç»“æœ
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        num_samples: é¢„è§ˆæ ·æœ¬æ•°é‡
    """
    print(f"ğŸ” é¢„è§ˆè½¬æ¢ç»“æœ (å‰{num_samples}æ¡):")
    print("=" * 60)
    
    with open(input_file, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= num_samples:
                break
                
            line = line.strip()
            if not line:
                continue
                
            try:
                # åŸå§‹æ•°æ®
                input_data = json.loads(line)
                print(f"ğŸ“‹ æ ·æœ¬ {i+1} - åŸå§‹æ ¼å¼:")
                print(f"  instruction: {input_data.get('instruction', '')[:100]}...")
                print(f"  input: {input_data.get('input', '')[:50]}...")
                print(f"  output: {input_data.get('output', '')[:100]}...")
                print(f"  category: {input_data.get('category', '')}")
                
                # è½¬æ¢åæ•°æ®
                converted_data = convert_ontothink_to_enflame(input_data)
                print(f"ğŸ”„ è½¬æ¢åæ ¼å¼:")
                print(f"  user: {converted_data['conversation'][0]['content'][:100]}...")
                print(f"  assistant: {converted_data['conversation'][1]['content'][:100]}...")
                print("-" * 40)
                
            except Exception as e:
                print(f"  âŒ æ ·æœ¬{i+1}è§£æå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ OntoThink â†’ ç‡§åŸChatGLM3 æ•°æ®æ ¼å¼è½¬æ¢å™¨")
    print("=" * 50)
    
    # å®šä¹‰æ–‡ä»¶è·¯å¾„
    base_dir = "/workspace/code/OntoThink_V4"
    input_dir = f"{base_dir}/backend/data/processed"
    output_dir = f"{base_dir}/enflame_training/datasets/ontothink_multiturn"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # æ–‡ä»¶æ˜ å°„
    file_mappings = [
        ("train.jsonl", "train.jsonl"),
        ("val.jsonl", "val.jsonl"), 
        ("test.jsonl", "test.jsonl")
    ]
    
    for input_filename, output_filename in file_mappings:
        input_file = f"{input_dir}/{input_filename}"
        output_file = f"{output_dir}/{output_filename}"
        
        if os.path.exists(input_file):
            print(f"\nğŸ“‚ å¤„ç†æ–‡ä»¶: {input_filename}")
            
            # é¢„è§ˆè½¬æ¢
            preview_conversion(input_file, num_samples=2)
            
            # æ‰§è¡Œè½¬æ¢
            convert_file(input_file, output_file)
            
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
    
    print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # éªŒè¯è½¬æ¢ç»“æœ
    print(f"\nğŸ” éªŒè¯è½¬æ¢ç»“æœ:")
    for _, output_filename in file_mappings:
        output_file = f"{output_dir}/{output_filename}"
        if os.path.exists(output_file):
            with open(output_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                print(f"  {output_filename}: {len(lines)} æ¡æ•°æ®")
                
                # éªŒè¯ç¬¬ä¸€æ¡æ•°æ®æ ¼å¼
                if lines:
                    try:
                        first_data = json.loads(lines[0])
                        if 'conversation' in first_data and len(first_data['conversation']) >= 2:
                            first_conv = first_data['conversation'][0]
                            if 'role' in first_conv and 'content' in first_conv:
                                print(f"    âœ… æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«roleå’Œcontentå­—æ®µ")
                            else:
                                print(f"    âŒ æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘roleæˆ–contentå­—æ®µ")
                        else:
                            print(f"    âŒ æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘conversationå­—æ®µæˆ–å¯¹è¯ä¸å®Œæ•´")
                    except Exception as e:
                        print(f"    âŒ æ ¼å¼éªŒè¯å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
