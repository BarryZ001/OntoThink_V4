#!/bin/bash

# ğŸ”§ ä¿®æ­£çš„å•GCUè®­ç»ƒæµ‹è¯•
# ä½¿ç”¨ç‡§åŸè„šæœ¬çš„æ­£ç¡®å‚æ•°æ ¼å¼
# ==============================

echo "ğŸ”§ ä¿®æ­£çš„å•GCUè®­ç»ƒæµ‹è¯•"
echo "ä½¿ç”¨ç‡§åŸè„šæœ¬çš„æ­£ç¡®å‚æ•°æ ¼å¼"
echo "==========================="

echo ""
echo "ğŸ”¥ ç¡¬ä»¶ç¯å¢ƒç¡®è®¤ï¼š"
echo "âœ… 8å¼ ç‡§åŸT20å¡å…¨éƒ¨æ­£å¸¸"
echo "âœ… æ¯å¼ 32GBå†…å­˜"
echo "âœ… æ¸©åº¦å’ŒåŠŸè€—æ­£å¸¸"

echo ""
echo "ğŸ”§ è®¾ç½®ç‡§åŸT20å•GCUç¯å¢ƒ"
echo "========================"

# ç‡§åŸT20ç¯å¢ƒå˜é‡ï¼ˆå•GCUï¼‰
export ENFLAME_ENABLE_EFP=true
export ENFLAME_PT_ENABLE_HBM_INPLACE=true
export OMP_NUM_THREADS=5
export ECCL_MAX_NCHANNELS=1
export ENFLAME_UMD_FLAGS="mem_alloc_retry_times=1"
export GCU_VISIBLE_DEVICES=0  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªGCU

echo "âœ… ç‡§åŸå•GCUç¯å¢ƒè®¾ç½®å®Œæˆ"

echo ""
echo "ğŸš€ å¯åŠ¨ä¿®æ­£çš„å•GCUè®­ç»ƒæµ‹è¯•"
echo "============================"

# ç‡§åŸè„šæœ¬ç›®å½•
ENFLAME_SCRIPT_DIR="/workspace/code/OntoThink_V4/FromEnflame/ai_development_toolkit/distributed/llm_scripts_1.0.40/finetuning/chatglm3"

if [ ! -f "$ENFLAME_SCRIPT_DIR/finetune_chatglm3_for_multiturn.py" ]; then
    echo "âŒ è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨"
    exit 1
fi

echo "âœ… æ‰¾åˆ°è®­ç»ƒè„šæœ¬: $ENFLAME_SCRIPT_DIR"
cd "$ENFLAME_SCRIPT_DIR"

echo ""
echo "ğŸ”§ ä½¿ç”¨ç‡§åŸæ”¯æŒçš„å‚æ•°å¯åŠ¨å•GCUè®­ç»ƒ..."

# ä½¿ç”¨ç‡§åŸè„šæœ¬æ”¯æŒçš„å‚æ•°ï¼Œå•å¡é…ç½®
python3.8 finetune_chatglm3_for_multiturn.py \
    --model_path "/workspace/code/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b" \
    --train_file "/workspace/code/OntoThink_V4/enflame_training/datasets/ontothink_multiturn/train.jsonl" \
    --tp_size 1 \
    --dp_size 1 \
    --pp_size 1 \
    --train_micro_batch_size 1 \
    --gradient_accumulation_steps 8 \
    --max_steps 3 \
    --max_tokens 512 \
    --ladder_shape False \
    --skip_steps 1 \
    --eval_batch_size 1 \
    --eval_per_n_epochs 1 \
    --train_epochs 1 2>&1 | tee /tmp/single_gcu_corrected.log

echo ""
echo "ğŸ” æµ‹è¯•ç»“æœåˆ†æ"
echo "================"

if [ -f /tmp/single_gcu_corrected.log ]; then
    echo "ğŸ“‹ æ£€æŸ¥æœ€æ–°çš„è¾“å‡º:"
    tail -20 /tmp/single_gcu_corrected.log
    
    echo ""
    echo "ğŸ“‹ æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯:"
    if grep -q -i "error\|fail\|exception\|traceback" /tmp/single_gcu_corrected.log; then
        echo "âŒ å‘ç°é”™è¯¯:"
        grep -i -A3 -B1 "error\|fail\|exception\|traceback" /tmp/single_gcu_corrected.log | tail -10
    else
        echo "âœ… æ²¡æœ‰å‘ç°æ˜æ˜¾é”™è¯¯"
    fi
    
    echo ""
    echo "ğŸ“‹ æ£€æŸ¥æ˜¯å¦æˆåŠŸåˆå§‹åŒ–ï¼š"
    if grep -q -i "collie\|config\|model\|tokenizer" /tmp/single_gcu_corrected.log; then
        echo "âœ… æ‰¾åˆ°åˆå§‹åŒ–ä¿¡æ¯:"
        grep -i "collie\|config\|model\|tokenizer" /tmp/single_gcu_corrected.log | head -5
    fi
    
    echo ""
    echo "ğŸ“‹ æ£€æŸ¥æ˜¯å¦å¼€å§‹è®­ç»ƒï¼š"
    if grep -q -i "training\|epoch\|step\|loss\|optimizer" /tmp/single_gcu_corrected.log; then
        echo "âœ… æ‰¾åˆ°è®­ç»ƒä¿¡æ¯:"
        grep -i "training\|epoch\|step\|loss\|optimizer" /tmp/single_gcu_corrected.log | tail -5
    else
        echo "âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒç›¸å…³ä¿¡æ¯"
    fi
    
    echo ""
    echo "ğŸ“‹ æ£€æŸ¥ç‡§åŸç‰¹å®šä¿¡æ¯ï¼š"
    if grep -q -i "ptex\|collie\|gcu\|eccl" /tmp/single_gcu_corrected.log; then
        echo "ğŸ”¥ æ‰¾åˆ°ç‡§åŸç›¸å…³ä¿¡æ¯:"
        grep -i "ptex\|collie\|gcu\|eccl" /tmp/single_gcu_corrected.log | head -3
    fi
fi

echo ""
echo "ğŸ’¡ å•GCUä¿®æ­£æµ‹è¯•æ€»ç»“"
echo "===================="

echo "ğŸ¯ å¦‚æœè¿™æ¬¡æµ‹è¯•æˆåŠŸï¼š"
echo "  âœ… å•å¡è®­ç»ƒç¯å¢ƒå®Œå…¨æ­£å¸¸"
echo "  âœ… é—®é¢˜ç¡®å®åœ¨8å¡åˆ†å¸ƒå¼é…ç½®"
echo "  ğŸ”§ å»ºè®®ï¼šé€æ­¥å¢åŠ å¡æ•° (1â†’2â†’4â†’8)"

echo ""
echo "ğŸ¯ å¦‚æœä»ç„¶å¤±è´¥ï¼š"
echo "  ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„å’Œå®Œæ•´æ€§"
echo "  ğŸ” æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼"
echo "  ğŸ” æ£€æŸ¥ç‡§åŸç¯å¢ƒé…ç½®"

echo ""
echo "ğŸ“‹ æ—¥å¿—æ–‡ä»¶: /tmp/single_gcu_corrected.log"

echo ""
echo "ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®ï¼š"
echo "1. å¦‚æœå•GCUæˆåŠŸï¼Œå°è¯• 2å¡è®­ç»ƒ (pp_size=2)"
echo "2. å¦‚æœå•GCUæˆåŠŸï¼Œå°è¯• 4å¡è®­ç»ƒ (pp_size=4)"  
echo "3. æœ€åå°è¯• 8å¡è®­ç»ƒ (pp_size=8)"
