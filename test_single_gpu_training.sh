#!/bin/bash
# å•GPUè®­ç»ƒæµ‹è¯•è„šæœ¬ - ç»•è¿‡åˆ†å¸ƒå¼è®­ç»ƒé—®é¢˜
# é€‚ç”¨äºŽç‡§åŽŸT20çŽ¯å¢ƒ

set -e

echo "ðŸš€ å•GPUè®­ç»ƒæµ‹è¯•"
echo "ç»•è¿‡åˆ†å¸ƒå¼è®­ç»ƒå¤æ‚æ€§ï¼Œç›´æŽ¥æµ‹è¯•åŸºç¡€è®­ç»ƒåŠŸèƒ½"
echo "========================================"

# è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ONTOTHINK_ROOT="$SCRIPT_DIR"

echo "ðŸ“ é¡¹ç›®æ ¹ç›®å½•: $ONTOTHINK_ROOT"

# æŸ¥æ‰¾ç‡§åŽŸChatGLM3è„šæœ¬ç›®å½•
CHATGLM3_SCRIPT_DIRS=(
    "${ONTOTHINK_ROOT}/FromEnflame/ai_development_toolkit/distributed/llm_scripts_1.0.40/finetuning/chatglm3"
    "/installer/topsrider_extracted/TopsRider_installer/ai_development_toolkit/distributed/llm_scripts_1.0.40/finetuning/chatglm3"
    "${ONTOTHINK_ROOT}/FromEnflame/distributed/llm_scripts_1.0.40/finetuning/chatglm3"
)

CHATGLM3_SCRIPT_DIR=""
for dir in "${CHATGLM3_SCRIPT_DIRS[@]}"; do
    if [ -d "$dir" ] && [ -f "$dir/finetune_chatglm3_for_multiturn.py" ]; then
        CHATGLM3_SCRIPT_DIR="$dir"
        echo "âœ… æ‰¾åˆ°ChatGLM3è„šæœ¬ç›®å½•: $dir"
        break
    fi
done

if [ -z "$CHATGLM3_SCRIPT_DIR" ]; then
    echo "âŒ æœªæ‰¾åˆ°ChatGLM3è„šæœ¬ç›®å½•"
    exit 1
fi

cd "$CHATGLM3_SCRIPT_DIR"
echo "ðŸ“ å½“å‰ç›®å½•: $PWD"

# è®¾ç½®è®­ç»ƒå‚æ•°
MODEL_PATH="${ONTOTHINK_ROOT}/enflame_training/models/THUDM/chatglm3-6b"
TRAIN_DATA_PATH="${ONTOTHINK_ROOT}/enflame_training/datasets/ontothink_multiturn/train.jsonl"
OUTPUT_DIR="${ONTOTHINK_ROOT}/enflame_training/models/ontothink-chatglm3-6b-test"

echo ""
echo "ðŸ“‹ è®­ç»ƒé…ç½®:"
echo "   æ¨¡åž‹è·¯å¾„: $MODEL_PATH"
echo "   è®­ç»ƒæ•°æ®: $TRAIN_DATA_PATH"
echo "   è¾“å‡ºç›®å½•: $OUTPUT_DIR"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$OUTPUT_DIR"

# è®¾ç½®å•GPUçŽ¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
export WORLD_SIZE=1
export RANK=0
export LOCAL_RANK=0

# æ¸…é™¤å¯èƒ½å¹²æ‰°çš„åˆ†å¸ƒå¼çŽ¯å¢ƒå˜é‡
unset MASTER_ADDR
unset MASTER_PORT

echo ""
echo "ðŸ”§ çŽ¯å¢ƒè®¾ç½®:"
echo "   CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
echo "   WORLD_SIZE: $WORLD_SIZE"
echo "   RANK: $RANK"
echo "   LOCAL_RANK: $LOCAL_RANK"

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if [ ! -f "$TRAIN_DATA_PATH" ]; then
    echo "âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: $TRAIN_DATA_PATH"
    echo "ðŸ”§ åˆ›å»ºæµ‹è¯•æ•°æ®..."
    
    # åˆ›å»ºæ•°æ®ç›®å½•
    mkdir -p "$(dirname "$TRAIN_DATA_PATH")"
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    cat > "$TRAIN_DATA_PATH" << 'EOF'
{"conversations": [{"from": "human", "value": "ä½ å¥½"}, {"from": "gpt", "value": "ä½ å¥½ï¼æˆ‘æ˜¯ChatGLM3ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚"}]}
{"conversations": [{"from": "human", "value": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"}, {"from": "gpt", "value": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚"}]}
{"conversations": [{"from": "human", "value": "è¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ "}, {"from": "gpt", "value": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿ç”¨ç®—æ³•å’Œç»Ÿè®¡æ¨¡åž‹è®©è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»Žæ•°æ®ä¸­å­¦ä¹ å’Œæ”¹è¿›ã€‚"}]}
EOF
    
    echo "âœ… åˆ›å»ºäº†æµ‹è¯•æ•°æ®æ–‡ä»¶"
fi

echo ""
echo "ðŸš€ å¼€å§‹å•GPUè®­ç»ƒæµ‹è¯•..."
echo "â±ï¸  è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."

# ä½¿ç”¨æœ€ç®€å•çš„å‚æ•°è¿›è¡Œæµ‹è¯•
python3 finetune_chatglm3_for_multiturn.py \
    --model_path "$MODEL_PATH" \
    --train_data_path "$TRAIN_DATA_PATH" \
    --output_dir "$OUTPUT_DIR" \
    --max_seq_length 512 \
    --num_train_epochs 1 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --learning_rate 1e-5 \
    --logging_steps 1 \
    --save_steps 10 \
    --save_total_limit 1 \
    --remove_unused_columns false \
    --dataloader_pin_memory false \
    --fp16 false \
    --report_to none \
    --evaluation_strategy no \
    --do_train \
    --overwrite_output_dir

if [ $? -eq 0 ]; then
    echo ""
    echo "ðŸŽ‰ å•GPUè®­ç»ƒæµ‹è¯•æˆåŠŸ!"
    echo ""
    echo "âœ… è¿™è¯´æ˜ŽåŸºç¡€è®­ç»ƒåŠŸèƒ½æ­£å¸¸ï¼Œé—®é¢˜å¯èƒ½åœ¨äºŽ:"
    echo "   1. åˆ†å¸ƒå¼è®­ç»ƒé…ç½®"
    echo "   2. 8GPUå¹¶è¡Œè®¾ç½®"
    echo "   3. ç‡§åŽŸT20å¤šå¡é€šä¿¡"
    echo ""
    echo "ðŸ”§ å»ºè®®å°è¯•:"
    echo "   1. ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼Œä½¿ç”¨è¾ƒå°‘çš„GPU"
    echo "   2. æ£€æŸ¥å¤šå¡é€šä¿¡è®¾ç½®"
    echo "   3. é€æ­¥å¢žåŠ GPUæ•°é‡æµ‹è¯•"
    echo ""
    echo "ðŸ“ æµ‹è¯•è¾“å‡ºç›®å½•: $OUTPUT_DIR"
    echo "ðŸ“Š æ£€æŸ¥è¾“å‡ºæ–‡ä»¶:"
    ls -la "$OUTPUT_DIR"
    
else
    echo ""
    echo "âŒ å•GPUè®­ç»ƒæµ‹è¯•ä¹Ÿå¤±è´¥"
    echo ""
    echo "ðŸ”§ è¿™è¡¨æ˜Žé—®é¢˜å¯èƒ½åœ¨äºŽ:"
    echo "   1. æ¨¡åž‹æ–‡ä»¶ä»æœ‰é—®é¢˜"
    echo "   2. PythonçŽ¯å¢ƒä¾èµ–"
    echo "   3. ç‡§åŽŸT20ç‰¹å®šé…ç½®"
    echo ""
    echo "ðŸ’¡ ä¸‹ä¸€æ­¥è°ƒè¯•:"
    echo "   bash $ONTOTHINK_ROOT/debug_training_detailed.sh"
fi
