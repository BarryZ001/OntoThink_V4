# ChatGLM3 æœ¬åœ°ä¸‹è½½ + æœåŠ¡å™¨ä¸Šä¼ æ–¹æ¡ˆ

## ðŸš€ æ–¹æ¡ˆä¼˜åŠ¿
- åˆ©ç”¨æœ¬åœ°Macç½‘ç»œä¼˜åŠ¿
- é¿å…æœåŠ¡å™¨ç½‘ç»œé™åˆ¶
- ä¸€æ¬¡ä¸‹è½½ï¼Œå¤šæ¬¡ä½¿ç”¨
- å¯éªŒè¯æ–‡ä»¶å®Œæ•´æ€§

## ðŸ“¥ ç¬¬ä¸€æ­¥ï¼šæœ¬åœ°Macä¸‹è½½

### æ–¹æ³•1ï¼šä½¿ç”¨æˆ‘ä»¬çš„Pythonè„šæœ¬ä¸‹è½½
```bash
# åœ¨æœ¬åœ°Macæ‰§è¡Œ
cd /Users/barryzhang/myDev3/OntoThink_V4

# è¿è¡Œæ™ºèƒ½ä¸‹è½½è„šæœ¬
python3 enflame_training/scripts/manual_download_chatglm3.py

# ä¸‹è½½å®ŒæˆåŽæ£€æŸ¥æ–‡ä»¶
ls -la enflame_training/models/THUDM/chatglm3-6b/
```

### æ–¹æ³•2ï¼šä½¿ç”¨huggingface_hubä¸‹è½½
```bash
# å®‰è£…huggingface_hub
pip install huggingface_hub

# ä¸‹è½½æ¨¡åž‹
python3 -c "
from huggingface_hub import snapshot_download
import os

# ä¸‹è½½åˆ°æœ¬åœ°
local_dir = '/Users/barryzhang/myDev3/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b'
os.makedirs(local_dir, exist_ok=True)

print('ðŸ“¥ å¼€å§‹ä¸‹è½½ChatGLM3-6B...')
snapshot_download(
    repo_id='THUDM/chatglm3-6b',
    local_dir=local_dir,
    local_dir_use_symlinks=False,
    resume_download=True
)
print('âœ… ä¸‹è½½å®Œæˆ!')
"
```

### æ–¹æ³•3ï¼šä½¿ç”¨git clone + LFS
```bash
# ç¡®ä¿å®‰è£…äº†git-lfs
brew install git-lfs
git lfs install

# åˆ›å»ºä¸‹è½½ç›®å½•
mkdir -p /Users/barryzhang/myDev3/OntoThink_V4/enflame_training/models/THUDM
cd /Users/barryzhang/myDev3/OntoThink_V4/enflame_training/models/THUDM

# å…‹éš†ä»“åº“
git clone https://huggingface.co/THUDM/chatglm3-6b

# ç¡®ä¿LFSæ–‡ä»¶ä¸‹è½½
cd chatglm3-6b
git lfs pull
```

## ðŸ“¤ ç¬¬äºŒæ­¥ï¼šéªŒè¯ä¸‹è½½æ–‡ä»¶

```bash
# æ£€æŸ¥å…³é”®æ–‡ä»¶
cd /Users/barryzhang/myDev3/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b

echo "ðŸ” æ£€æŸ¥æ–‡ä»¶å¤§å°..."

# æ£€æŸ¥tokenizer
if [ -f "tokenizer.model" ]; then
    size=$(stat -f%z "tokenizer.model")
    echo "tokenizer.model: $size bytes"
    if [ $size -gt 1000000 ]; then
        echo "âœ… tokenizer.model å¤§å°æ­£å¸¸"
    else
        echo "âŒ tokenizer.model è¿‡å°"
    fi
else
    echo "âŒ tokenizer.model ä¸å­˜åœ¨"
fi

# æ£€æŸ¥æƒé‡æ–‡ä»¶
echo ""
echo "ðŸ“‹ æƒé‡æ–‡ä»¶æ£€æŸ¥:"
for i in {1..7}; do
    file="model-0000${i}-of-00007.safetensors"
    if [ -f "$file" ]; then
        size=$(stat -f%z "$file")
        echo "$file: $size bytes"
    else
        file="pytorch_model-0000${i}-of-00007.bin"
        if [ -f "$file" ]; then
            size=$(stat -f%z "$file")
            echo "$file: $size bytes"
        else
            echo "âŒ æƒé‡æ–‡ä»¶ $i ä¸å­˜åœ¨"
        fi
    fi
done

# æ£€æŸ¥é…ç½®æ–‡ä»¶
echo ""
echo "ðŸ“‹ é…ç½®æ–‡ä»¶æ£€æŸ¥:"
for file in "config.json" "tokenizer_config.json" "modeling_chatglm.py" "tokenization_chatglm.py"; do
    if [ -f "$file" ]; then
        echo "âœ… $file"
    else
        echo "âŒ $file ç¼ºå¤±"
    fi
done
```

## ðŸ“¤ ç¬¬ä¸‰æ­¥ï¼šä¸Šä¼ åˆ°æœåŠ¡å™¨

### æ–¹æ³•1ï¼šä½¿ç”¨rsyncï¼ˆæŽ¨èï¼‰
```bash
# åŽ‹ç¼©å¹¶ä¸Šä¼ 
cd /Users/barryzhang/myDev3/OntoThink_V4/enflame_training/models/THUDM

# å…ˆåŽ‹ç¼©ï¼ˆå¯é€‰ï¼ŒèŠ‚çœä¼ è¾“æ—¶é—´ï¼‰
tar -czf chatglm3-6b.tar.gz chatglm3-6b/

# ä¸Šä¼ åŽ‹ç¼©æ–‡ä»¶
rsync -avz --progress -e "ssh -p 60025" \
    chatglm3-6b.tar.gz \
    root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/

# æˆ–è€…ç›´æŽ¥ä¸Šä¼ ç›®å½•ï¼ˆä¸åŽ‹ç¼©ï¼‰
rsync -avz --progress -e "ssh -p 60025" \
    chatglm3-6b/ \
    root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b/
```

### æ–¹æ³•2ï¼šä½¿ç”¨scp
```bash
# ä¸Šä¼ åŽ‹ç¼©æ–‡ä»¶
scp -P 60025 -r chatglm3-6b.tar.gz \
    root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/

# æˆ–è€…ç›´æŽ¥ä¸Šä¼ ç›®å½•
scp -P 60025 -r chatglm3-6b \
    root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/
```

## ðŸ–¥ï¸ ç¬¬å››æ­¥ï¼šæœåŠ¡å™¨ç«¯è§£åŽ‹å’ŒéªŒè¯

### ç™»å½•æœåŠ¡å™¨
```bash
ssh -p 60025 root@117.156.108.234
```

### è§£åŽ‹æ–‡ä»¶ï¼ˆå¦‚æžœä¸Šä¼ çš„æ˜¯åŽ‹ç¼©åŒ…ï¼‰
```bash
cd /workspace/code/OntoThink_V4/enflame_training/models/THUDM

# è§£åŽ‹
tar -xzf chatglm3-6b.tar.gz

# åˆ é™¤åŽ‹ç¼©åŒ…
rm chatglm3-6b.tar.gz

# æ£€æŸ¥æ–‡ä»¶
ls -la chatglm3-6b/
```

### éªŒè¯ä¸Šä¼ ç»“æžœ
```bash
cd /workspace/code/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b

# æ£€æŸ¥tokenizer
python3 -c "
import sentencepiece as spm
try:
    sp = smp.SentencePieceProcessor()
    sp.load('tokenizer.model')
    print('âœ… tokenizeréªŒè¯é€šè¿‡')
except Exception as e:
    print(f'âŒ tokenizeréªŒè¯å¤±è´¥: {e}')
"

# æ£€æŸ¥æ–‡ä»¶æ•°é‡
echo "ðŸ“‹ æ–‡ä»¶ç»Ÿè®¡:"
echo "æƒé‡æ–‡ä»¶æ•°é‡: $(ls model-*.safetensors pytorch_model-*.bin 2>/dev/null | wc -l)"
echo "é…ç½®æ–‡ä»¶æ•°é‡: $(ls *.json *.py 2>/dev/null | wc -l)"
echo "æ€»æ–‡ä»¶æ•°é‡: $(ls -1 | wc -l)"
```

## ðŸš€ ç¬¬äº”æ­¥ï¼šå¼€å§‹è®­ç»ƒ

```bash
# åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œ
cd /workspace/code/OntoThink_V4

# è¿è¡Œè®­ç»ƒ
python3 enflame_training/scripts/train_ontothink_enflame.py --step full
```

## ðŸ’¡ ä¼˜åŒ–æŠ€å·§

### 1. å¹¶è¡Œä¸‹è½½ï¼ˆå¦‚æžœç½‘ç»œå…è®¸ï¼‰
```bash
# ä½¿ç”¨aria2cå¹¶è¡Œä¸‹è½½
brew install aria2

# åˆ›å»ºä¸‹è½½è„šæœ¬
cat > download_chatglm3.sh << 'EOF'
#!/bin/bash
BASE_URL="https://huggingface.co/THUDM/chatglm3-6b/resolve/main"
OUTPUT_DIR="/Users/barryzhang/myDev3/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b"

mkdir -p "$OUTPUT_DIR"
cd "$OUTPUT_DIR"

# å¹¶è¡Œä¸‹è½½æ–‡ä»¶
aria2c -x 4 -s 4 "${BASE_URL}/config.json"
aria2c -x 4 -s 4 "${BASE_URL}/tokenizer.model"
aria2c -x 4 -s 4 "${BASE_URL}/tokenizer_config.json"
aria2c -x 4 -s 4 "${BASE_URL}/modeling_chatglm.py"
aria2c -x 4 -s 4 "${BASE_URL}/tokenization_chatglm.py"

# ä¸‹è½½æƒé‡æ–‡ä»¶
for i in {1..7}; do
    aria2c -x 4 -s 4 "${BASE_URL}/model-0000${i}-of-00007.safetensors"
done
EOF

chmod +x download_chatglm3.sh
./download_chatglm3.sh
```

### 2. æ–­ç‚¹ç»­ä¼ 
```bash
# rsyncæ”¯æŒæ–­ç‚¹ç»­ä¼ 
rsync -avz --progress --partial -e "ssh -p 60025" \
    chatglm3-6b/ \
    root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b/
```

### 3. åŽ‹ç¼©ä¼ è¾“
```bash
# ä½¿ç”¨æ›´å¥½çš„åŽ‹ç¼©ç®—æ³•
tar -cf - chatglm3-6b | pigz | \
    ssh -p 60025 root@117.156.108.234 \
    "cd /workspace/code/OntoThink_V4/enflame_training/models/THUDM && pigz -d | tar -xf -"
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´**ï¼šæ¨¡åž‹æ–‡ä»¶çº¦13GBï¼Œç¡®ä¿æœ¬åœ°å’ŒæœåŠ¡å™¨éƒ½æœ‰è¶³å¤Ÿç©ºé—´
2. **ç½‘ç»œç¨³å®šæ€§**ï¼šå¤§æ–‡ä»¶ä¼ è¾“å»ºè®®ä½¿ç”¨rsyncçš„æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
3. **æ–‡ä»¶æƒé™**ï¼šä¸Šä¼ åŽæ£€æŸ¥æ–‡ä»¶æƒé™æ˜¯å¦æ­£ç¡®
4. **è·¯å¾„ä¸€è‡´æ€§**ï¼šç¡®ä¿æœåŠ¡å™¨è·¯å¾„ä¸Žè®­ç»ƒè„šæœ¬é¢„æœŸä¸€è‡´

## ðŸ” æ•…éšœæŽ’é™¤

### å¦‚æžœä¸Šä¼ ä¸­æ–­
```bash
# ä½¿ç”¨rsyncæ¢å¤ä¸Šä¼ 
rsync -avz --progress --partial -e "ssh -p 60025" \
    chatglm3-6b/ \
    root@117.156.108.234:/workspace/code/OntoThink_V4/enflame_training/models/THUDM/chatglm3-6b/
```

### å¦‚æžœæ–‡ä»¶æŸå
```bash
# åœ¨æœåŠ¡å™¨ä¸ŠéªŒè¯æ–‡ä»¶
cd /workspace/code/OntoThink_V4
python3 enflame_training/scripts/manual_download_chatglm3.py
```
