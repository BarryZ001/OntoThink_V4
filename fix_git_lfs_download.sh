#!/bin/bash
# ä¿®å¤Git LFSä¸‹è½½é—®é¢˜ - ç›´æ¥ä¸‹è½½å®é™…æ–‡ä»¶
# é€‚ç”¨äºç‡§åŸT20ç¯å¢ƒ

set -e

echo "ğŸ”§ Git LFSä¸‹è½½ä¿®å¤å·¥å…·"
echo "========================================"

# è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ONTOTHINK_ROOT="$SCRIPT_DIR"
MODEL_DIR="${ONTOTHINK_ROOT}/enflame_training/models/THUDM/chatglm3-6b"

echo "ğŸ“ é¡¹ç›®æ ¹ç›®å½•: $ONTOTHINK_ROOT"
echo "ğŸ“ æ¨¡å‹ç›®å½•: $MODEL_DIR"

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨Git LFSæŒ‡é’ˆæ–‡ä»¶
if [ -d "$MODEL_DIR" ]; then
    echo ""
    echo "ğŸ” æ£€æŸ¥å½“å‰æ–‡ä»¶çŠ¶æ€..."
    
    # æ£€æŸ¥tokenizer.modelå¤§å°
    if [ -f "$MODEL_DIR/tokenizer.model" ]; then
        TOKENIZER_SIZE=$(stat -c%s "$MODEL_DIR/tokenizer.model" 2>/dev/null || echo "0")
        echo "ğŸ“‹ å½“å‰tokenizer.modelå¤§å°: $TOKENIZER_SIZE bytes"
        
        if [ "$TOKENIZER_SIZE" -lt 1000000 ]; then  # å°äº1MBè¯´æ˜æ˜¯æŒ‡é’ˆæ–‡ä»¶
            echo "âš ï¸  æ£€æµ‹åˆ°Git LFSæŒ‡é’ˆæ–‡ä»¶ï¼Œéœ€è¦ç›´æ¥ä¸‹è½½å®é™…æ–‡ä»¶"
            NEED_DOWNLOAD=true
        else
            echo "âœ… tokenizer.modelæ–‡ä»¶æ­£å¸¸"
            NEED_DOWNLOAD=false
        fi
    else
        echo "âŒ tokenizer.modelæ–‡ä»¶ä¸å­˜åœ¨"
        NEED_DOWNLOAD=true
    fi
    
    # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶
    WEIGHT_FILE="$MODEL_DIR/model-00001-of-00007.safetensors"
    if [ -f "$WEIGHT_FILE" ]; then
        WEIGHT_SIZE=$(stat -c%s "$WEIGHT_FILE" 2>/dev/null || echo "0")
        echo "ğŸ“‹ å½“å‰æƒé‡æ–‡ä»¶å¤§å°: $WEIGHT_SIZE bytes"
        
        if [ "$WEIGHT_SIZE" -lt 1000000 ]; then  # å°äº1MBè¯´æ˜æ˜¯æŒ‡é’ˆæ–‡ä»¶
            echo "âš ï¸  æ£€æµ‹åˆ°Git LFSæƒé‡æ–‡ä»¶æŒ‡é’ˆï¼Œéœ€è¦ç›´æ¥ä¸‹è½½"
            NEED_DOWNLOAD=true
        fi
    fi
else
    echo "âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨"
    NEED_DOWNLOAD=true
fi

if [ "$NEED_DOWNLOAD" != "true" ]; then
    echo "âœ… æ¨¡å‹æ–‡ä»¶å·²æ­£å¸¸ï¼Œæ— éœ€é‡æ–°ä¸‹è½½"
    exit 0
fi

echo ""
echo "ğŸ”„ å¼€å§‹ä½¿ç”¨HTTPç›´æ¥ä¸‹è½½æ¨¡å‹æ–‡ä»¶..."

# æ¸…ç†æŸåçš„ç›®å½•
if [ -d "$MODEL_DIR" ]; then
    echo "ğŸ§¹ æ¸…ç†æŸåçš„æ¨¡å‹ç›®å½•..."
    rm -rf "$MODEL_DIR"
fi

# åˆ›å»ºç›®å½•
mkdir -p "$MODEL_DIR"
cd "$MODEL_DIR"

echo "ğŸ“ åˆ‡æ¢åˆ°æ¨¡å‹ç›®å½•: $PWD"

# ModelScope HTTPä¸‹è½½å‡½æ•°
download_from_modelscope() {
    echo "ğŸ”„ æ–¹æ³•1: ä½¿ç”¨ModelScope HTTPç›´æ¥ä¸‹è½½..."
    
    local BASE_URL="https://www.modelscope.cn/api/v1/models/ZhipuAI/chatglm3-6b/repo?Revision=master&FilePath="
    
    # å…³é”®æ–‡ä»¶åˆ—è¡¨
    local FILES=(
        "config.json"
        "configuration_chatglm.py" 
        "modeling_chatglm.py"
        "tokenization_chatglm.py"
        "tokenizer_config.json"
        "special_tokens_map.json"
        "MODEL_LICENSE"
        "README.md"
        "quantization.py"
        "model.safetensors.index.json"
        "pytorch_model.bin.index.json"
        "tokenizer.model"
    )
    
    # ä¸‹è½½é…ç½®æ–‡ä»¶
    echo "ğŸ“¥ ä¸‹è½½é…ç½®æ–‡ä»¶..."
    for file in "${FILES[@]}"; do
        echo "  - ä¸‹è½½ $file..."
        if wget -q --timeout=60 "${BASE_URL}${file}" -O "$file"; then
            echo "    âœ… $file ä¸‹è½½æˆåŠŸ"
        else
            echo "    âŒ $file ä¸‹è½½å¤±è´¥ï¼Œå°è¯•curl..."
            if curl -s --connect-timeout 60 "${BASE_URL}${file}" -o "$file"; then
                echo "    âœ… $file (curl) ä¸‹è½½æˆåŠŸ"
            else
                echo "    âš ï¸  $file ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡"
            fi
        fi
    done
    
    # ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶ (safetensorsæ ¼å¼ä¼˜å…ˆ)
    echo "ğŸ“¥ ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶..."
    local WEIGHT_FILES=(
        "model-00001-of-00007.safetensors"
        "model-00002-of-00007.safetensors" 
        "model-00003-of-00007.safetensors"
        "model-00004-of-00007.safetensors"
        "model-00005-of-00007.safetensors"
        "model-00006-of-00007.safetensors"
        "model-00007-of-00007.safetensors"
    )
    
    for weight_file in "${WEIGHT_FILES[@]}"; do
        echo "  - ä¸‹è½½ $weight_file..."
        if wget -q --timeout=300 "${BASE_URL}${weight_file}" -O "$weight_file"; then
            local file_size=$(stat -c%s "$weight_file" 2>/dev/null || echo "0")
            if [ "$file_size" -gt 1000000 ]; then  # å¤§äº1MB
                echo "    âœ… $weight_file ä¸‹è½½æˆåŠŸ (${file_size} bytes)"
            else
                echo "    âš ï¸  $weight_file å¯èƒ½ä¸‹è½½ä¸å®Œæ•´ï¼Œå°è¯•curl..."
                if curl -s --connect-timeout 300 "${BASE_URL}${weight_file}" -o "$weight_file"; then
                    file_size=$(stat -c%s "$weight_file" 2>/dev/null || echo "0")
                    echo "    âœ… $weight_file (curl) ä¸‹è½½æˆåŠŸ (${file_size} bytes)"
                else
                    echo "    âŒ $weight_file ä¸‹è½½å¤±è´¥"
                fi
            fi
        else
            echo "    âŒ $weight_file wgetå¤±è´¥ï¼Œå°è¯•curl..."
            if curl -s --connect-timeout 300 "${BASE_URL}${weight_file}" -o "$weight_file"; then
                local file_size=$(stat -c%s "$weight_file" 2>/dev/null || echo "0")
                echo "    âœ… $weight_file (curl) ä¸‹è½½æˆåŠŸ (${file_size} bytes)"
            else
                echo "    âŒ $weight_file ä¸‹è½½å¤±è´¥"
            fi
        fi
    done
}

# Hugging Face HTTPä¸‹è½½å‡½æ•°  
download_from_huggingface() {
    echo "ğŸ”„ æ–¹æ³•2: ä½¿ç”¨Hugging Face HTTPç›´æ¥ä¸‹è½½..."
    
    local BASE_URL="https://huggingface.co/THUDM/chatglm3-6b/resolve/main/"
    
    # ä¸‹è½½tokenizer.model (æœ€é‡è¦)
    echo "ğŸ“¥ ä¼˜å…ˆä¸‹è½½tokenizer.model..."
    if wget -q --timeout=300 "${BASE_URL}tokenizer.model" -O "tokenizer.model"; then
        local file_size=$(stat -c%s "tokenizer.model" 2>/dev/null || echo "0")
        if [ "$file_size" -gt 1000000 ]; then
            echo "    âœ… tokenizer.model ä¸‹è½½æˆåŠŸ (${file_size} bytes)"
            return 0
        else
            echo "    âš ï¸  tokenizer.model å¤§å°å¼‚å¸¸ï¼Œå°è¯•curl..."
        fi
    fi
    
    if curl -s --connect-timeout 300 "${BASE_URL}tokenizer.model" -o "tokenizer.model"; then
        local file_size=$(stat -c%s "tokenizer.model" 2>/dev/null || echo "0")
        echo "    âœ… tokenizer.model (curl) ä¸‹è½½æˆåŠŸ (${file_size} bytes)"
        return 0
    else
        echo "    âŒ tokenizer.model ä¸‹è½½å¤±è´¥"
        return 1
    fi
}

# ä½¿ç”¨Python huggingface_hubä¸‹è½½
download_with_python() {
    echo "ğŸ”„ æ–¹æ³•3: ä½¿ç”¨Python huggingface_hubä¸‹è½½..."
    
    python3 -c "
import os
import sys
try:
    from huggingface_hub import hf_hub_download
    import requests
    
    print('ğŸ“¥ ä¸‹è½½tokenizer.model...')
    try:
        # å°è¯•ä¸‹è½½tokenizer.model
        tokenizer_path = hf_hub_download(
            repo_id='THUDM/chatglm3-6b',
            filename='tokenizer.model',
            cache_dir=None,
            local_dir='.',
            local_dir_use_symlinks=False
        )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.exists('./tokenizer.model'):
            size = os.path.getsize('./tokenizer.model')
            if size > 1000000:  # å¤§äº1MB
                print(f'âœ… tokenizer.model ä¸‹è½½æˆåŠŸ ({size} bytes)')
                sys.exit(0)
            else:
                print(f'âš ï¸  tokenizer.model å¤§å°å¼‚å¸¸ ({size} bytes)')
        
    except Exception as e:
        print(f'âŒ huggingface_hubä¸‹è½½å¤±è´¥: {e}')
        
    # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥HTTPä¸‹è½½
    print('ğŸ“¥ å°è¯•ç›´æ¥HTTPä¸‹è½½...')
    try:
        import urllib.request
        url = 'https://huggingface.co/THUDM/chatglm3-6b/resolve/main/tokenizer.model'
        urllib.request.urlretrieve(url, './tokenizer.model')
        
        if os.path.exists('./tokenizer.model'):
            size = os.path.getsize('./tokenizer.model')
            print(f'âœ… tokenizer.model HTTPä¸‹è½½æˆåŠŸ ({size} bytes)')
            sys.exit(0)
    except Exception as e:
        print(f'âŒ HTTPä¸‹è½½å¤±è´¥: {e}')
        
    sys.exit(1)
        
except ImportError:
    print('âŒ æœªå®‰è£…huggingface_hubï¼Œè·³è¿‡Pythonä¸‹è½½æ–¹æ³•')
    sys.exit(1)
"
}

# å°è¯•å¤šç§ä¸‹è½½æ–¹æ³•
echo "ğŸ”„ å°è¯•å¤šç§ä¸‹è½½æ–¹æ³•..."

# æ–¹æ³•1: ModelScope HTTP
download_from_modelscope

# æ£€æŸ¥tokenizer.modelæ˜¯å¦ä¸‹è½½æˆåŠŸ
if [ -f "tokenizer.model" ]; then
    TOKENIZER_SIZE=$(stat -c%s "tokenizer.model")
    if [ "$TOKENIZER_SIZE" -gt 1000000 ]; then
        echo "âœ… ModelScopeä¸‹è½½æˆåŠŸ"
    else
        echo "âš ï¸  ModelScopeä¸‹è½½çš„tokenizer.modelå¤§å°å¼‚å¸¸ï¼Œå°è¯•å…¶ä»–æ–¹æ³•..."
        
        # æ–¹æ³•2: Hugging Face HTTP
        download_from_huggingface
        
        # æ–¹æ³•3: Python huggingface_hub
        if [ ! -f "tokenizer.model" ] || [ "$(stat -c%s "tokenizer.model")" -lt 1000000 ]; then
            download_with_python
        fi
    fi
else
    echo "âŒ ModelScopeä¸‹è½½å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•..."
    
    # æ–¹æ³•2: Hugging Face HTTP  
    download_from_huggingface
    
    # æ–¹æ³•3: Python huggingface_hub
    if [ ! -f "tokenizer.model" ] || [ "$(stat -c%s "tokenizer.model")" -lt 1000000 ]; then
        download_with_python
    fi
fi

echo ""
echo "ğŸ” æ£€æŸ¥ä¸‹è½½ç»“æœ..."

# éªŒè¯å…³é”®æ–‡ä»¶
if [ -f "config.json" ]; then
    echo "âœ… config.json å­˜åœ¨"
else
    echo "âŒ config.json ç¼ºå¤±"
fi

if [ -f "tokenizer.model" ]; then
    FINAL_SIZE=$(stat -c%s "tokenizer.model")
    echo "âœ… tokenizer.model å­˜åœ¨ (${FINAL_SIZE} bytes)"
    
    if [ "$FINAL_SIZE" -gt 1000000 ]; then
        echo "âœ… tokenizer.model å¤§å°æ­£å¸¸"
    else
        echo "âŒ tokenizer.model å¤§å°å¼‚å¸¸ï¼Œå¯èƒ½ä»æ˜¯æŒ‡é’ˆæ–‡ä»¶"
    fi
else
    echo "âŒ tokenizer.model ç¼ºå¤±"
fi

# æ£€æŸ¥æƒé‡æ–‡ä»¶
WEIGHT_COUNT=0
for i in {1..7}; do
    weight_file="model-0000${i}-of-00007.safetensors"
    if [ -f "$weight_file" ]; then
        file_size=$(stat -c%s "$weight_file")
        if [ "$file_size" -gt 1000000 ]; then
            ((WEIGHT_COUNT++))
            echo "âœ… $weight_file å­˜åœ¨ä¸”å¤§å°æ­£å¸¸ (${file_size} bytes)"
        else
            echo "âš ï¸  $weight_file å­˜åœ¨ä½†å¤§å°å¼‚å¸¸ (${file_size} bytes)"
        fi
    else
        echo "âŒ $weight_file ç¼ºå¤±"
    fi
done

if [ "$WEIGHT_COUNT" -gt 0 ]; then
    echo "âœ… æœ‰ $WEIGHT_COUNT ä¸ªæƒé‡æ–‡ä»¶ä¸‹è½½æˆåŠŸ"
else
    echo "âŒ æ‰€æœ‰æƒé‡æ–‡ä»¶ä¸‹è½½å¤±è´¥"
fi

echo ""
echo "ğŸ“Š å½“å‰ç›®å½•å†…å®¹:"
ls -la

echo ""
echo "ğŸ‰ Git LFSä¸‹è½½ä¿®å¤å®Œæˆï¼"

# éªŒè¯tokenizeråŠŸèƒ½
echo ""
echo "ğŸ“‹ éªŒè¯tokenizeråŠŸèƒ½..."
if [ -f "tokenizer.model" ]; then
    FINAL_TOKENIZER_SIZE=$(stat -c%s "tokenizer.model")
    echo "âœ… æœ€ç»ˆtokenizer.modelå¤§å°: $FINAL_TOKENIZER_SIZE bytes"
    
    if [ "$FINAL_TOKENIZER_SIZE" -gt 1000000 ]; then
        # éªŒè¯tokenizerå®Œæ•´æ€§
        python3 -c "
import sentencepiece as smp
try:
    sp = smp.SentencePieceProcessor()
    sp.load('tokenizer.model')
    print('âœ… tokenizeréªŒè¯é€šè¿‡')
except Exception as e:
    print(f'âŒ tokenizeréªŒè¯å¤±è´¥: {e}')
    exit(1)
" 2>/dev/null
        
        if [ $? -eq 0 ]; then
            echo "ğŸ‰ tokenizerä¿®å¤æˆåŠŸï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†"
        else
            echo "âŒ tokenizeråŠŸèƒ½éªŒè¯å¤±è´¥"
        fi
    else
        echo "âŒ tokenizer.modelæ–‡ä»¶ä»ç„¶å¤ªå°"
    fi
else
    echo "âŒ tokenizer.modelæ–‡ä»¶ä»ç„¶ç¼ºå¤±"
fi

echo ""
echo "ğŸ“‹ ä¸‹ä¸€æ­¥:"
echo "cd $ONTOTHINK_ROOT"
echo "python3 enflame_training/scripts/train_ontothink_enflame.py --step full"