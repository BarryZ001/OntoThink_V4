#!/usr/bin/env python3
"""
OntoThinkè®­ç»ƒæ•°æ®æ‰©å±•è„šæœ¬
ä½¿ç”¨ç°æœ‰ç§å­æ•°æ®ç”Ÿæˆæ›´å¤šé«˜è´¨é‡çš„è®­ç»ƒæ ·æœ¬
"""

import json
import random
import asyncio
import aiohttp
from typing import List, Dict
import argparse
from pathlib import Path

# å“²å­¦é¢†åŸŸå’Œé—®é¢˜æ¨¡æ¿
PHILOSOPHY_DOMAINS = {
    "å½¢è€Œä¸Šå­¦": [
        "å­˜åœ¨çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æ—¶é—´æ˜¯çœŸå®å­˜åœ¨çš„è¿˜æ˜¯äººç±»è®¤çŸ¥çš„äº§ç‰©ï¼Ÿ",
        "ç©ºé—´æ˜¯æ— é™çš„å—ï¼Ÿ",
        "å› æœå…³ç³»æ˜¯å¿…ç„¶çš„å—ï¼Ÿ",
        "ä¸ªä½“æ€§çš„åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ"
    ],
    "è®¤è¯†è®º": [
        "çŸ¥è¯†çš„ç•Œé™åœ¨å“ªé‡Œï¼Ÿ",
        "æ„Ÿæ€§ç»éªŒèƒ½å¦æä¾›å¯é çš„çŸ¥è¯†ï¼Ÿ",
        "ç†æ€§ä¸ç»éªŒå“ªä¸ªæ›´é‡è¦ï¼Ÿ",
        "æ€€ç–‘ä¸»ä¹‰æ˜¯å¦æœ‰é“ç†ï¼Ÿ",
        "çœŸç†çš„æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ"
    ],
    "ä¼¦ç†å­¦": [
        "é“å¾·çš„åŸºç¡€æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ä¸ªäººå¹¸ç¦ä¸ç¤¾ä¼šåˆ©ç›Šå¦‚ä½•å¹³è¡¡ï¼Ÿ",
        "å–„æ¶çš„æ ‡å‡†æ˜¯æ™®éçš„å—ï¼Ÿ",
        "é“å¾·è´£ä»»çš„å‰ææ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç¾å¾·ä¸è§„åˆ™å“ªä¸ªæ›´é‡è¦ï¼Ÿ"
    ],
    "ç¾å­¦": [
        "ç¾çš„æ ‡å‡†æ˜¯å®¢è§‚çš„å—ï¼Ÿ",
        "è‰ºæœ¯çš„æœ¬è´¨æ˜¯æ¨¡ä»¿è¿˜æ˜¯åˆ›é€ ï¼Ÿ",
        "å®¡ç¾ç»éªŒçš„ç‹¬ç‰¹æ€§ä½•åœ¨ï¼Ÿ",
        "è‰ºæœ¯ä¸ç°å®çš„å…³ç³»å¦‚ä½•ï¼Ÿ",
        "ç¾ä¸å–„ã€çœŸçš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ"
    ],
    "å¿ƒçµå“²å­¦": [
        "æ„è¯†çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¿ƒçµä¸èº«ä½“çš„å…³ç³»å¦‚ä½•ï¼Ÿ",
        "äººå·¥æ™ºèƒ½èƒ½å¦äº§ç”ŸçœŸæ­£çš„æ„è¯†ï¼Ÿ",
        "è‡ªæˆ‘è®¤åŒçš„æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æƒ…æ„Ÿåœ¨è®¤çŸ¥ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ"
    ],
    "æ”¿æ²»å“²å­¦": [
        "ç†æƒ³çš„æ”¿æ²»åˆ¶åº¦æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ä¸ªäººè‡ªç”±ä¸ç¤¾ä¼šç§©åºå¦‚ä½•å¹³è¡¡ï¼Ÿ",
        "æ­£ä¹‰çš„åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æƒåŠ›çš„åˆæ³•æ€§æ¥æºä½•åœ¨ï¼Ÿ",
        "å…¬æ°‘ä¸æœä»åœ¨ä»€ä¹ˆæƒ…å†µä¸‹æ˜¯æ­£å½“çš„ï¼Ÿ"
    ]
}

def generate_philosophical_questions(num_questions: int = 50) -> List[str]:
    """ç”Ÿæˆå¤šæ ·åŒ–çš„å“²å­¦é—®é¢˜"""
    questions = []
    
    # ä»ç°æœ‰æ¨¡æ¿ç”Ÿæˆ
    for domain, domain_questions in PHILOSOPHY_DOMAINS.items():
        questions.extend(domain_questions)
    
    # ç”Ÿæˆç»„åˆé—®é¢˜
    combined_questions = [
        "å¦‚æœ{}ï¼Œé‚£ä¹ˆ{}ï¼Ÿ".format(
            random.choice(["è‡ªç”±æ„å¿—ä¸å­˜åœ¨", "é“å¾·æ˜¯ç›¸å¯¹çš„", "çŸ¥è¯†æ˜¯æœ‰é™çš„", "ç¾æ˜¯ä¸»è§‚çš„"]),
            random.choice(["è´£ä»»å¦‚ä½•å®šä¹‰", "ä»·å€¼å¦‚ä½•è¡¡é‡", "çœŸç†å¦‚ä½•è¿½æ±‚", "åˆ›é€ å¦‚ä½•å¯èƒ½"])
        )
        for _ in range(10)
    ]
    
    questions.extend(combined_questions)
    
    # ç”Ÿæˆå¯¹æ¯”é—®é¢˜
    contrast_questions = [
        "{}ä¸{}ï¼šå“ªä¸ªæ›´æ ¹æœ¬ï¼Ÿ".format(
            random.choice(["ç†æ€§", "æ„Ÿæ€§", "ä¸ªä½“", "é›†ä½“", "è‡ªç”±", "ç§©åº"]),
            random.choice(["æƒ…æ„Ÿ", "ç›´è§‰", "ç¤¾ä¼š", "ä¸ªäºº", "å®‰å…¨", "åˆ›æ–°"])
        )
        for _ in range(10)
    ]
    
    questions.extend(contrast_questions)
    
    return random.sample(questions, min(num_questions, len(questions)))

async def generate_with_deepseek(session: aiohttp.ClientSession, question: str, api_key: str) -> Dict:
    """ä½¿ç”¨DeepSeek APIç”Ÿæˆæ€è¾¨æ•°æ®"""
    
    prompt = f"""è¯·åŸºäºä»¥ä¸‹å“²å­¦é—®é¢˜ï¼Œç”ŸæˆåŒ…å«ä¸åŒç«‹åœºã€æ”¯æŒè®ºæ®å’Œåé—®çš„æ€è¾¨å›¾è°±æ•°æ®ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
  "question": "{question}",
  "standpoints": [
    {{
      "id": "standpoint_1",
      "text": "[ç«‹åœº1çš„é™ˆè¿°]",
      "arguments": [
        {{
          "id": "argument_1_1",
          "text": "[æ”¯æŒç«‹åœº1çš„è®ºæ®1]"
        }},
        {{
          "id": "argument_1_2",
          "text": "[æ”¯æŒç«‹åœº1çš„è®ºæ®2]"
        }}
      ]
    }},
    {{
      "id": "standpoint_2",
      "text": "[ç«‹åœº2çš„é™ˆè¿°]",
      "arguments": [
        {{
          "id": "argument_2_1",
          "text": "[æ”¯æŒç«‹åœº2çš„è®ºæ®1]"
        }},
        {{
          "id": "argument_2_2",
          "text": "[æ”¯æŒç«‹åœº2çš„è®ºæ®2]"
        }}
      ]
    }}
  ],
  "counter_questions": [
    {{
      "id": "counter_question_1",
      "text": "[é’ˆå¯¹ä¸Šè¿°ç«‹åœºæˆ–è®ºæ®çš„åé—®1]"
    }},
    {{
      "id": "counter_question_2",
      "text": "[é’ˆå¯¹ä¸Šè¿°ç«‹åœºæˆ–è®ºæ®çš„åé—®2]"
    }}
  ]
}}

è¦æ±‚ï¼š
1. ç«‹åœºåº”è¯¥å¯¹ç«‹æˆ–äº’è¡¥ï¼Œä½“ç°é—®é¢˜çš„å¤æ‚æ€§
2. è®ºæ®è¦æœ‰å“²å­¦æ·±åº¦ï¼Œé¿å…å¸¸è¯†æ€§è¡¨è¿°
3. åé—®è¦èƒ½å¼•å‘æ·±å±‚æ€è€ƒï¼ŒæŒ‘æˆ˜ç°æœ‰è§‚ç‚¹
4. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œæ‰€æœ‰å­—æ®µå®Œæ•´

é—®é¢˜ï¼š{question}"""

    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 2000
    }
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        async with session.post(
            "https://api.deepseek.com/v1/chat/completions",
            json=payload,
            headers=headers
        ) as response:
            if response.status == 200:
                result = await response.json()
                content = result["choices"][0]["message"]["content"].strip()
                
                # å°è¯•è§£æJSON
                try:
                    # æå–JSONéƒ¨åˆ†
                    start = content.find('{')
                    end = content.rfind('}') + 1
                    if start != -1 and end != 0:
                        json_content = content[start:end]
                        data = json.loads(json_content)
                        return data
                    else:
                        print(f"âš ï¸  æ— æ³•æå–JSON: {question}")
                        return None
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  JSONè§£æå¤±è´¥: {question} - {e}")
                    return None
            else:
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status}")
                return None
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
        return None

def convert_to_training_format(data: Dict) -> List[Dict]:
    """å°†æ€è¾¨æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼"""
    training_samples = []
    
    question = data["question"]
    
    # ç”Ÿæˆç«‹åœº+è®ºæ®çš„è®­ç»ƒæ ·æœ¬
    for standpoint in data.get("standpoints", []):
        instruction = f"è¯·åŸºäºä»¥ä¸‹å“²å­¦é—®é¢˜ï¼Œæå‡ºä¸€ä¸ªæ˜ç¡®çš„ç«‹åœºå¹¶ç»™å‡ºæ”¯æŒè®ºæ®ï¼š\n\né—®é¢˜ï¼š{question}\n\nç«‹åœºï¼š{standpoint['text']}"
        
        arguments_text = "\n".join([
            f"- {arg['text']}" for arg in standpoint.get("arguments", [])
        ])
        
        output = f"è®ºæ®ï¼š\n{arguments_text}"
        
        training_samples.append({
            "instruction": instruction,
            "input": "",
            "output": output,
            "category": "å“²å­¦æ€è¾¨-ç«‹åœºè®ºæ®"
        })
    
    # ç”Ÿæˆåé—®çš„è®­ç»ƒæ ·æœ¬
    for i, cq in enumerate(data.get("counter_questions", [])):
        # éšæœºé€‰æ‹©ä¸€ä¸ªç«‹åœºä½œä¸ºåé—®çš„å¯¹è±¡
        if data.get("standpoints"):
            target_standpoint = random.choice(data["standpoints"])
            
            instruction = f"è¯·é’ˆå¯¹ä»¥ä¸‹å“²å­¦ç«‹åœºï¼Œæå‡ºä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åé—®ï¼š\n\né—®é¢˜ï¼š{question}\nç«‹åœºï¼š{target_standpoint['text']}\n"
            
            output = f"åé—®ï¼š{cq['text']}"
            
            training_samples.append({
                "instruction": instruction,
                "input": "",
                "output": output,
                "category": "å“²å­¦æ€è¾¨-åé—®"
            })
    
    return training_samples

async def generate_training_data(api_key: str, num_samples: int = 100, output_path: str = None):
    """æ‰¹é‡ç”Ÿæˆè®­ç»ƒæ•°æ®"""
    
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªè®­ç»ƒæ ·æœ¬...")
    
    # ç”Ÿæˆé—®é¢˜
    questions = generate_philosophical_questions(num_samples)
    
    all_training_samples = []
    successful_generations = 0
    
    async with aiohttp.ClientSession() as session:
        # é™åˆ¶å¹¶å‘æ•°é‡ä»¥é¿å…APIé™åˆ¶
        semaphore = asyncio.Semaphore(3)
        
        async def process_question(question):
            async with semaphore:
                print(f"ğŸ“ å¤„ç†é—®é¢˜: {question}")
                data = await generate_with_deepseek(session, question, api_key)
                
                if data:
                    training_samples = convert_to_training_format(data)
                    return training_samples
                return []
        
        # å¹¶å‘å¤„ç†æ‰€æœ‰é—®é¢˜
        tasks = [process_question(q) for q in questions]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, list) and result:
                all_training_samples.extend(result)
                successful_generations += 1
            elif isinstance(result, Exception):
                print(f"âŒ å¤„ç†å¼‚å¸¸: {result}")
    
    print(f"âœ… æˆåŠŸç”Ÿæˆ {len(all_training_samples)} ä¸ªè®­ç»ƒæ ·æœ¬ (æˆåŠŸç‡: {successful_generations}/{len(questions)})")
    
    # ä¿å­˜ç»“æœ
    if output_path:
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for sample in all_training_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜è‡³: {output_file}")
    
    return all_training_samples

def main():
    parser = argparse.ArgumentParser(description="æ‰©å±•OntoThinkè®­ç»ƒæ•°æ®")
    parser.add_argument("--api_key", required=True, help="DeepSeek APIå¯†é’¥")
    parser.add_argument("--num_samples", type=int, default=100, help="ç”Ÿæˆæ ·æœ¬æ•°é‡")
    parser.add_argument("--output_path", required=True, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # è¿è¡Œæ•°æ®ç”Ÿæˆ
    asyncio.run(generate_training_data(
        api_key=args.api_key,
        num_samples=args.num_samples,
        output_path=args.output_path
    ))

if __name__ == "__main__":
    main()
