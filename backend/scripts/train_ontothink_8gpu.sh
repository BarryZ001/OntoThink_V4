#!/bin/bash
# OntoThink ChatGLM3-6B 8å¡GCUåˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1

# æ¨¡å‹å’Œæ•°æ®è·¯å¾„
MODEL_NAME="THUDM/chatglm3-6b"
DATA_PATH="/Users/barryzhang/myDev3/OntoThink_V4/backend/data/processed"
OUTPUT_DIR="/Users/barryzhang/myDev3/OntoThink_V4/models/chatglm3-ontothink"
LOG_DIR="/Users/barryzhang/myDev3/OntoThink_V4/logs/training"

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p $OUTPUT_DIR
mkdir -p $LOG_DIR

# è®­ç»ƒå‚æ•°
NUM_GPUS=8
BATCH_SIZE_PER_GPU=2
GRADIENT_ACCUMULATION_STEPS=4
EFFECTIVE_BATCH_SIZE=$((NUM_GPUS * BATCH_SIZE_PER_GPU * GRADIENT_ACCUMULATION_STEPS))

echo "ğŸš€ å¼€å§‹OntoThinkæ¨¡å‹è®­ç»ƒ"
echo "ğŸ“Š è®­ç»ƒé…ç½®:"
echo "   - åŸºç¡€æ¨¡å‹: $MODEL_NAME"
echo "   - GPUæ•°é‡: $NUM_GPUS"
echo "   - æ¯GPUæ‰¹æ¬¡å¤§å°: $BATCH_SIZE_PER_GPU"
echo "   - æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: $GRADIENT_ACCUMULATION_STEPS"
echo "   - æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: $EFFECTIVE_BATCH_SIZE"
echo "   - è¾“å‡ºç›®å½•: $OUTPUT_DIR"

# ä½¿ç”¨torchrunè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
torchrun --nproc_per_node=$NUM_GPUS \
    --master_port=29500 \
    /Users/barryzhang/myDev3/OntoThink_V4/backend/app/training/chatglm3_ontothink_training.py \
    --model_name_or_path $MODEL_NAME \
    --data_path $DATA_PATH \
    --output_dir $OUTPUT_DIR \
    --num_train_epochs 3 \
    --per_device_train_batch_size $BATCH_SIZE_PER_GPU \
    --per_device_eval_batch_size $BATCH_SIZE_PER_GPU \
    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
    --evaluation_strategy "steps" \
    --eval_steps 100 \
    --save_strategy "steps" \
    --save_steps 200 \
    --save_total_limit 3 \
    --learning_rate 5e-5 \
    --weight_decay 0.01 \
    --warmup_ratio 0.03 \
    --lr_scheduler_type "cosine" \
    --logging_steps 10 \
    --bf16 True \
    --tf32 True \
    --gradient_checkpointing True \
    --dataloader_pin_memory False \
    --ddp_find_unused_parameters False \
    --use_lora True \
    --lora_r 64 \
    --lora_alpha 128 \
    --lora_dropout 0.05 \
    --q_lora True \
    --max_seq_length 2048 \
    --report_to "tensorboard" \
    --logging_dir "$LOG_DIR" \
    --seed 42 \
    --remove_unused_columns False \
    2>&1 | tee "$LOG_DIR/training_$(date +%Y%m%d_%H%M%S).log"

echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "ğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®: $OUTPUT_DIR"
echo "ğŸ“Š è®­ç»ƒæ—¥å¿—ä½ç½®: $LOG_DIR"

# è®­ç»ƒå®Œæˆåçš„éªŒè¯
echo "ğŸ” å¼€å§‹æ¨¡å‹éªŒè¯..."
python /Users/barryzhang/myDev3/OntoThink_V4/backend/scripts/validate_model.py \
    --model_path $OUTPUT_DIR \
    --test_data_path "$DATA_PATH/test.jsonl" \
    --output_path "$OUTPUT_DIR/validation_results.json"

echo "ğŸ‰ OntoThinkæ¨¡å‹è®­ç»ƒå’ŒéªŒè¯å®Œæˆï¼"
