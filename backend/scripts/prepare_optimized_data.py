#!/usr/bin/env python3
"""
OntoThinkä¼˜åŒ–æ•°æ®å‡†å¤‡è„šæœ¬
é’ˆå¯¹ChatGLM3è®­ç»ƒè¿›è¡Œæ•°æ®æ ¼å¼ä¼˜åŒ–
"""

import json
import random
from pathlib import Path
from typing import List, Dict
import argparse
from sklearn.model_selection import train_test_split

def load_existing_data(data_dir: str) -> List[Dict]:
    """åŠ è½½ç°æœ‰çš„è®­ç»ƒæ•°æ®"""
    all_data = []
    
    # åŠ è½½ç°æœ‰çš„JSONLæ–‡ä»¶
    for file_path in ["train.jsonl", "val.jsonl", "test.jsonl"]:
        full_path = Path(data_dir) / file_path
        if full_path.exists():
            with open(full_path, 'r', encoding='utf-8') as f:
                for line in f:
                    all_data.append(json.loads(line))
    
    print(f"ğŸ“Š åŠ è½½ç°æœ‰æ•°æ®: {len(all_data)} æ¡")
    return all_data

def optimize_instruction_format(data: List[Dict]) -> List[Dict]:
    """ä¼˜åŒ–æŒ‡ä»¤æ ¼å¼ï¼Œä½¿å…¶æ›´é€‚åˆChatGLM3è®­ç»ƒ"""
    
    optimized_data = []
    
    for item in data:
        # åŸå§‹æ ¼å¼
        instruction = item.get("instruction", "")
        input_text = item.get("input", "")
        output = item.get("output", "")
        category = item.get("category", "é€šç”¨")
        
        # åˆ›å»ºChatGLM3æ ¼å¼çš„ä¼˜åŒ–æŒ‡ä»¤
        if "ç«‹åœº" in instruction and "è®ºæ®" in instruction:
            # ç«‹åœº+è®ºæ®ç±»å‹
            new_instruction = "ä½ æ˜¯OntoThinkæ€è¾¨åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç»™å®šçš„å“²å­¦é—®é¢˜å’Œç«‹åœºï¼Œæä¾›æ·±å…¥çš„è®ºè¯æ”¯æŒã€‚"
            new_input = instruction.replace("è¯·åŸºäºä»¥ä¸‹å“²å­¦é—®é¢˜ï¼Œæå‡ºä¸€ä¸ªæ˜ç¡®çš„ç«‹åœºå¹¶ç»™å‡ºæ”¯æŒè®ºæ®ï¼š", "").strip()
            new_output = output
            
        elif "åé—®" in instruction:
            # åé—®ç±»å‹
            new_instruction = "ä½ æ˜¯OntoThinkæ€è¾¨åŠ©æ‰‹ã€‚è¯·é’ˆå¯¹ç»™å®šçš„å“²å­¦ç«‹åœºï¼Œæå‡ºå…·æœ‰å¯å‘æ€§å’ŒæŒ‘æˆ˜æ€§çš„åé—®ã€‚"
            new_input = instruction.replace("è¯·é’ˆå¯¹ä»¥ä¸‹å“²å­¦ç«‹åœºï¼Œæå‡ºä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åé—®ï¼š", "").strip()
            new_output = output
            
        elif "æ€è¾¨å›¾è°±" in instruction:
            # å®Œæ•´å›¾è°±ç”Ÿæˆç±»å‹
            new_instruction = "ä½ æ˜¯OntoThinkæ€è¾¨åŠ©æ‰‹ã€‚è¯·ä¸ºç»™å®šçš„å“²å­¦é—®é¢˜ç”Ÿæˆå®Œæ•´çš„æ€è¾¨å›¾è°±ï¼ŒåŒ…å«å¤šä¸ªç«‹åœºã€è®ºæ®å’Œåé—®ã€‚è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"
            new_input = instruction.replace("è¯·åŸºäºä»¥ä¸‹å“²å­¦é—®é¢˜ï¼Œç”ŸæˆåŒ…å«ä¸åŒç«‹åœºã€æ”¯æŒè®ºæ®å’Œåé—®çš„æ€è¾¨å›¾è°±æ•°æ®ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼š", "").strip()
            new_output = output
            
        else:
            # ä¿æŒåŸæ ¼å¼
            new_instruction = instruction
            new_input = input_text
            new_output = output
        
        optimized_data.append({
            "instruction": new_instruction,
            "input": new_input,
            "output": new_output,
            "category": category,
            "task_type": classify_task_type(new_instruction, new_output)
        })
    
    return optimized_data

def classify_task_type(instruction: str, output: str) -> str:
    """åˆ†ç±»ä»»åŠ¡ç±»å‹"""
    if "JSON" in output or "{" in output:
        return "graph_generation"
    elif "è®ºæ®" in output or "argument" in output.lower():
        return "argument_generation"
    elif "åé—®" in output or "counter" in output.lower():
        return "counter_question"
    else:
        return "general_reasoning"

def balance_dataset(data: List[Dict]) -> List[Dict]:
    """å¹³è¡¡æ•°æ®é›†ï¼Œç¡®ä¿å„ç±»ä»»åŠ¡åˆ†å¸ƒåˆç†"""
    
    # æŒ‰ä»»åŠ¡ç±»å‹åˆ†ç»„
    task_groups = {}
    for item in data:
        task_type = item.get("task_type", "general_reasoning")
        if task_type not in task_groups:
            task_groups[task_type] = []
        task_groups[task_type].append(item)
    
    print("ğŸ“Š ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
    for task_type, items in task_groups.items():
        print(f"   - {task_type}: {len(items)} æ¡")
    
    # ç¡®ä¿æ¯ç§ä»»åŠ¡ç±»å‹è‡³å°‘æœ‰ä¸€å®šæ•°é‡çš„æ ·æœ¬
    min_samples_per_type = 50
    balanced_data = []
    
    for task_type, items in task_groups.items():
        if len(items) < min_samples_per_type:
            # å¦‚æœæ ·æœ¬ä¸è¶³ï¼Œè¿›è¡Œé‡å¤é‡‡æ ·
            repeated_items = []
            while len(repeated_items) < min_samples_per_type:
                repeated_items.extend(items)
            balanced_data.extend(repeated_items[:min_samples_per_type])
        else:
            balanced_data.extend(items)
    
    # éšæœºæ‰“ä¹±
    random.shuffle(balanced_data)
    
    print(f"âš–ï¸  å¹³è¡¡åæ•°æ®é›†å¤§å°: {len(balanced_data)} æ¡")
    return balanced_data

def add_system_prompts(data: List[Dict]) -> List[Dict]:
    """ä¸ºæ•°æ®æ·»åŠ ç³»ç»Ÿæç¤ºï¼Œå¢å¼ºæ¨¡å‹çš„è§’è‰²è®¤çŸ¥"""
    
    system_prompts = {
        "graph_generation": "ä½ æ˜¯OntoThinkä¸“ä¸šæ€è¾¨å›¾è°±ç”ŸæˆåŠ©æ‰‹ï¼Œæ“…é•¿å°†å¤æ‚å“²å­¦é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–çš„å¤šç»´åº¦åˆ†æã€‚",
        "argument_generation": "ä½ æ˜¯OntoThinkè®ºè¯åˆ†æä¸“å®¶ï¼Œä¸“é—¨ä¸ºå„ç§å“²å­¦ç«‹åœºæä¾›æ·±å…¥ã€ä¸¥è°¨çš„è®ºè¯æ”¯æŒã€‚",
        "counter_question": "ä½ æ˜¯OntoThinkè‹æ ¼æ‹‰åº•å¼æé—®ä¸“å®¶ï¼Œæ“…é•¿é€šè¿‡å·§å¦™çš„åé—®å¼•å¯¼æ›´æ·±å±‚æ¬¡çš„æ€è¾¨ã€‚",
        "general_reasoning": "ä½ æ˜¯OntoThinké€šç”¨æ€è¾¨åŠ©æ‰‹ï¼Œèƒ½å¤Ÿè¿›è¡Œå„ç§å½¢å¼çš„å“²å­¦æ¨ç†å’Œåˆ†æã€‚"
    }
    
    enhanced_data = []
    for item in data:
        task_type = item.get("task_type", "general_reasoning")
        system_prompt = system_prompts.get(task_type, system_prompts["general_reasoning"])
        
        # å°†ç³»ç»Ÿæç¤ºæ•´åˆåˆ°instructionä¸­
        enhanced_instruction = f"{system_prompt}\n\n{item['instruction']}"
        
        enhanced_data.append({
            "instruction": enhanced_instruction,
            "input": item["input"],
            "output": item["output"],
            "category": item["category"],
            "task_type": task_type
        })
    
    return enhanced_data

def create_test_samples() -> List[Dict]:
    """åˆ›å»ºä¸“é—¨çš„æµ‹è¯•æ ·æœ¬"""
    test_questions = [
        "äººå·¥æ™ºèƒ½æ˜¯å¦èƒ½å¤ŸçœŸæ­£ç†è§£è¯­è¨€ï¼Ÿ",
        "è‰ºæœ¯åˆ›ä½œä¸­çš„æƒ…æ„Ÿä¸æŠ€å·§å“ªä¸ªæ›´é‡è¦ï¼Ÿ",
        "åœ¨å¤šå…ƒæ–‡åŒ–ç¤¾ä¼šä¸­ï¼Œå¦‚ä½•å®šä¹‰å…±åŒä»·å€¼è§‚ï¼Ÿ",
        "ç§‘å­¦è¿›æ­¥æ˜¯å¦æ€»æ˜¯å¸¦æ¥é“å¾·è¿›æ­¥ï¼Ÿ",
        "ä¸ªäººéšç§ä¸ç¤¾ä¼šå®‰å…¨ä¹‹é—´çš„ç•Œé™åœ¨å“ªé‡Œï¼Ÿ"
    ]
    
    test_samples = []
    for question in test_questions:
        test_samples.append({
            "instruction": "ä½ æ˜¯OntoThinkä¸“ä¸šæ€è¾¨å›¾è°±ç”ŸæˆåŠ©æ‰‹ï¼Œæ“…é•¿å°†å¤æ‚å“²å­¦é—®é¢˜è½¬åŒ–ä¸ºç»“æ„åŒ–çš„å¤šç»´åº¦åˆ†æã€‚\n\nè¯·ä¸ºç»™å®šçš„å“²å­¦é—®é¢˜ç”Ÿæˆå®Œæ•´çš„æ€è¾¨å›¾è°±ï¼ŒåŒ…å«å¤šä¸ªç«‹åœºã€è®ºæ®å’Œåé—®ã€‚è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚",
            "input": f"é—®é¢˜ï¼š{question}",
            "output": "è¯·ç”Ÿæˆç¬¦åˆOntoThinkæ ¼å¼çš„æ€è¾¨å›¾è°±JSONæ•°æ®ã€‚",
            "category": "æµ‹è¯•æ ·æœ¬",
            "task_type": "graph_generation"
        })
    
    return test_samples

def split_and_save_data(data: List[Dict], output_dir: str, test_size: float = 0.1, val_size: float = 0.1):
    """åˆ†å‰²å¹¶ä¿å­˜æ•°æ®"""
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # æ·»åŠ ä¸“é—¨çš„æµ‹è¯•æ ·æœ¬
    test_samples = create_test_samples()
    
    # å…ˆåˆ†å‡ºæµ‹è¯•é›†
    train_val_data, test_data = train_test_split(
        data, 
        test_size=test_size, 
        random_state=42,
        stratify=[item["task_type"] for item in data]
    )
    
    # å†åˆ†å‡ºéªŒè¯é›†
    train_data, val_data = train_test_split(
        train_val_data,
        test_size=val_size/(1-test_size),
        random_state=42,
        stratify=[item["task_type"] for item in train_val_data]
    )
    
    # æ·»åŠ ä¸“é—¨çš„æµ‹è¯•æ ·æœ¬åˆ°æµ‹è¯•é›†
    test_data.extend(test_samples)
    
    # ä¿å­˜å„ä¸ªæ•°æ®é›†
    datasets = {
        "train": train_data,
        "val": val_data,
        "test": test_data
    }
    
    for split_name, split_data in datasets.items():
        output_file = output_path / f"{split_name}.jsonl"
        with open(output_file, 'w', encoding='utf-8') as f:
            for item in split_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ ä¿å­˜ {split_name} æ•°æ®: {len(split_data)} æ¡ -> {output_file}")
    
    # ä¿å­˜æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total_samples": len(data) + len(test_samples),
        "train_samples": len(train_data),
        "val_samples": len(val_data),
        "test_samples": len(test_data),
        "task_type_distribution": {}
    }
    
    all_data = train_data + val_data + test_data
    for item in all_data:
        task_type = item["task_type"]
        if task_type not in stats["task_type_distribution"]:
            stats["task_type_distribution"][task_type] = 0
        stats["task_type_distribution"][task_type] += 1
    
    with open(output_path / "data_stats.json", 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯ä¿å­˜è‡³: {output_path / 'data_stats.json'}")

def main():
    parser = argparse.ArgumentParser(description="å‡†å¤‡ä¼˜åŒ–çš„OntoThinkè®­ç»ƒæ•°æ®")
    parser.add_argument("--input_dir", required=True, help="è¾“å…¥æ•°æ®ç›®å½•")
    parser.add_argument("--output_dir", required=True, help="è¾“å‡ºæ•°æ®ç›®å½•")
    parser.add_argument("--test_size", type=float, default=0.1, help="æµ‹è¯•é›†æ¯”ä¾‹")
    parser.add_argument("--val_size", type=float, default=0.1, help="éªŒè¯é›†æ¯”ä¾‹")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹å‡†å¤‡ä¼˜åŒ–çš„è®­ç»ƒæ•°æ®...")
    
    # åŠ è½½ç°æœ‰æ•°æ®
    raw_data = load_existing_data(args.input_dir)
    
    if not raw_data:
        print("âŒ æœªæ‰¾åˆ°ç°æœ‰æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬")
        return
    
    # ä¼˜åŒ–æŒ‡ä»¤æ ¼å¼
    optimized_data = optimize_instruction_format(raw_data)
    
    # å¹³è¡¡æ•°æ®é›†
    balanced_data = balance_dataset(optimized_data)
    
    # æ·»åŠ ç³»ç»Ÿæç¤º
    enhanced_data = add_system_prompts(balanced_data)
    
    # åˆ†å‰²å¹¶ä¿å­˜æ•°æ®
    split_and_save_data(enhanced_data, args.output_dir, args.test_size, args.val_size)
    
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print(f"ğŸ“ ä¼˜åŒ–åçš„æ•°æ®ä¿å­˜åœ¨: {args.output_dir}")

if __name__ == "__main__":
    main()
